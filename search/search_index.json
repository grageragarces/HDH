{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the HDH library HDH refers to Hybrid Dependency Hypergraph , an abstraction developped to enable the partitioning of quantum computations in the context of Distributed Quantum Computing. HDHs are a directed hypergraph based abstraction that encodes the dependencies generated by entangling quantum operations displaying the state transformations performed along the computation. They aim to serve as a unifying abstraction capable of encoding any quantum workload regardless of the computational model it is designed in, that enables all valid partitions of a computation (superseding telegate and teledata abstractions). Furthermore HDHs, as their name implies, also encode classical information enabling the outline of natural classical partitioning points, such as mid-circuit measurements. You can find an in depth description of HDHs as an abstraction here: An introduction to HDHs . A more in-depth explanation of why HDHs make sense can be found here: Why HDHs? Further explanations of how HDHs are generated from quantum computational models can be found here: Generation of HDHs from model instructions . You can also find a Database with over 2000 HDHs here: HDH Database . The source code can be found: https://github.com/grageragarces/HDH . If you find any bugs or have any proposals for the library we encourage you to open an issue. A guide on how to do this can be found here . HDHs were originally developped by Maria Gragera Garces, Chris Heunen and Mahesh K. Marina. Publications, posters and talks related to the HDH project can be found here: Literature . The library is currently under MIT License. The development of this library was kindly supported by a Unitary Fund microgrant, as well as the Engineering and Physical Sciences Research Council (grant number EP/W524384/1), the University of Edinburgh, and VeriQloud .","title":"Home"},{"location":"#welcome-to-the-hdh-library","text":"HDH refers to Hybrid Dependency Hypergraph , an abstraction developped to enable the partitioning of quantum computations in the context of Distributed Quantum Computing. HDHs are a directed hypergraph based abstraction that encodes the dependencies generated by entangling quantum operations displaying the state transformations performed along the computation. They aim to serve as a unifying abstraction capable of encoding any quantum workload regardless of the computational model it is designed in, that enables all valid partitions of a computation (superseding telegate and teledata abstractions). Furthermore HDHs, as their name implies, also encode classical information enabling the outline of natural classical partitioning points, such as mid-circuit measurements. You can find an in depth description of HDHs as an abstraction here: An introduction to HDHs . A more in-depth explanation of why HDHs make sense can be found here: Why HDHs? Further explanations of how HDHs are generated from quantum computational models can be found here: Generation of HDHs from model instructions . You can also find a Database with over 2000 HDHs here: HDH Database . The source code can be found: https://github.com/grageragarces/HDH . If you find any bugs or have any proposals for the library we encourage you to open an issue. A guide on how to do this can be found here . HDHs were originally developped by Maria Gragera Garces, Chris Heunen and Mahesh K. Marina. Publications, posters and talks related to the HDH project can be found here: Literature . The library is currently under MIT License. The development of this library was kindly supported by a Unitary Fund microgrant, as well as the Engineering and Physical Sciences Research Council (grant number EP/W524384/1), the University of Edinburgh, and VeriQloud .","title":"Welcome to the HDH library"},{"location":"database/","text":"The HDH Database To support reproducible evaluation and training of partitioning strategies, this library includes a database of pre-generated HDHs. We aim for this resource to facilitate benchmarking across diverse workloads and enables the development of learning-based distribution agents. Our goal is to extend the database with performance metrics of partitioning techniques for each workload. This will allow the community to build a data-driven understanding of which hypergraph partitioning methods perform best under different conditions. We encourage users to contribute results from their own partitioning methods when working with this database. Instructions for how to upload results can be found below. Database Location and Structure The database is available in the database-branch of the repository . This separation ensures that users of the main library don't need to download unnecessary files. Important : The database exists only in the repository and is not included in the pip package or wheels . Users who want to use the database for benchmarking should clone the database-branch separately. The database is organized into two main directories: Database/ : Contains the actual database files (HDHs and workloads) Database_generator/ : Contains scripts, converters, and utilities for generating and extending the database Database Directory Structure Database/ \u251c\u2500\u2500 Workloads/ # Raw workload commands \u2502 \u2514\u2500\u2500 <Model>/ \u2502 \u2514\u2500\u2500 <Origin>/ \u2514\u2500\u2500 HDHs/ # Corresponding Hybrid Dependency Hypergraphs \u2514\u2500\u2500 <Model>/ \u2514\u2500\u2500 <Origin>/ \u251c\u2500\u2500 pkl/ # Pickled HDH objects \u251c\u2500\u2500 text/ # Human-readable CSV files \u251c\u2500\u2500 images/ # (reserved for future visualizations) \u2514\u2500\u2500 Partitions/ # Partitioning method results \u251c\u2500\u2500 partitions_all.csv \u2514\u2500\u2500 README.md where: * Model = computational model (e.g., Circuit, MBQC, QW, QCA) * Origin = source of the workload (e.g., benchmark suite, custom circuit) Database_generator Directory The Database_generator/ folder contains: * Conversion scripts (QASM \u2192 HDH) * Partitioning evaluation scripts * Utilities for batch processing * Configuration templates The database currently contains: HDHs derived from the Munich Quantum Benchmarking Dataset File Formats Workloads Directory QASM files representing the quantum workloads HDHs Directory .pkl : Python-pickled HDH objects for programmatic use .txt / .csv : Human-readable text files with annotated metadata __nodes.csv : Node information (node_id, type, time, realisation) __edges.csv : Edge information (edge_index, type, realisation, gate_name, role, edge_args, edge_metadata) __edge_members.csv : Edge-node relationships (edge_index, node_id) Partitions Directory partitions_all.csv : Partitioning results from various methods README.md : Documentation of partitioning methods used HDH Metadata Each HDH includes metadata describing: Model type : Which computational model the HDH was generated from Workload origin : Reference to the source workload Hybrid status : Whether the HDH contains both quantum and classical nodes Node count : Total number of nodes in the hypergraph Connectivity degree : Average connectivity of the hypergraph Disconnected subgraphs : Number of disconnected components Partitioning Performance Metrics Thanks to the recent additions in PR #24, the library now provides comprehensive metrics for evaluating partitioning quality. These metrics can be computed and added to the database to build a performance baseline. Available Metrics (from hdh.passes ) 1. cost(hdh_graph, partitions) \u2192 Tuple[float, float] Returns (cost_q, cost_c) - the quantum and classical cut costs: * cost_q : Number of quantum hyperedges that span multiple partitions * cost_c : Number of classical hyperedges that span multiple partitions This is the primary metric for comparing partitioning methods. 2. partition_size(partitions) \u2192 List[int] Returns the size (number of nodes) of each partition. Useful for checking balance constraints. 3. participation(hdh_graph, partitions) \u2192 Dict[str, float] Measures temporal participation (which partitions have activity at each timestep). Note : This measures presence, not true computational parallelism. Returns: * max_participation : Peak number of active partitions * average_participation : Mean active partitions per timestep * temporal_efficiency : How well time is utilized * partition_utilization : Average fraction of partitions active * timesteps : Total timesteps * num_partitions : Number of partitions 4. parallelism(hdh_graph, partitions) \u2192 Dict[str, float] Measures true parallelism by counting concurrent \u03c4-edges (operations) per timestep. This represents actual computational work that can execute simultaneously. Returns: * max_parallelism : Peak concurrent operations * average_parallelism : Mean operations per timestep * total_operations : Total operation count * timesteps : Total timesteps * num_partitions : Number of partitions 5. fair_parallelism(hdh_graph, partitions, capacities) \u2192 Dict[str, float] Implements Jean's fairness principle - normalizes parallelism by partition capacity to detect workload imbalances. Returns: * max_fair_parallelism : Peak fair parallelism * average_fair_parallelism : Mean fair parallelism * fairness_ratio : Distribution fairness (1.0 = perfectly fair) * total_operations : Total operation count * timesteps : Total timesteps * num_partitions : Number of partitions Usage Example from hdh.passes import ( cost, partition_size, participation, parallelism, fair_parallelism ) # After running your partitioning method bins, _, _, _ = your_partitioning_method(hdh_graph, k=3) # Evaluate the partition cost_q, cost_c = cost(hdh_graph, bins) sizes = partition_size(bins) participation_metrics = participation(hdh_graph, bins) parallelism_metrics = parallelism(hdh_graph, bins) fair_metrics = fair_parallelism(hdh_graph, bins, capacities=[10, 10, 10]) print(f\"Quantum cut cost: {cost_q}\") print(f\"Classical cut cost: {cost_c}\") print(f\"Partition sizes: {sizes}\") print(f\"Average parallelism: {parallelism_metrics['average_parallelism']}\") print(f\"Fairness ratio: {fair_metrics['fairness_ratio']}\") Extending the Dataset We encourage users to: Add new workloads (QASM or other supported formats ) Generate corresponding HDHs Run partitioning methods and contribute results Propose and document new metrics Pull requests that expand the benchmark set or enrich metadata are very welcome! How to Add to This Database There are two ways to contribute: 1) Add New Workloads + HDHs Step 1: Place Workloads Put your workload origin files under: Database/Workloads/<Model>/<Origin>/ This could be anything from a QASM file to circuit generation code. If the HDH is not generated from functions within the library, we request you add a README.md to your origin folder explaining how the HDHs were generated. Example: Database/Workloads/Circuits/MQTBench/qft_8.qasm Step 2: Run the Converter Convert the files (QASM strings, Qiskit circuits, etc.) to HDHs. The converter will create: Database/HDHs/<Model>/<Origin>/pkl/<filename>.pkl Database/HDHs/<Model>/<Origin>/text/<filename>__nodes.csv Database/HDHs/<Model>/<Origin>/text/<filename>__edges.csv Database/HDHs/<Model>/<Origin>/text/<filename>__edge_members.csv Converter Script (QASM \u2192 HDH \u2192 {pkl,csv}) The converter script is available in Database_generator/ folder. Requirements: tqdm, the HDH library available on PYTHONPATH, and your QASM converter ( hdh.converters.from_qasm ). #!/usr/bin/env python3 import sys import os import csv import json import pickle from pathlib import Path from tqdm import tqdm import argparse # Repo import path (adjust as needed) sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) from hdh.converters import from_qasm BASE_DIR = Path(__file__).resolve().parent def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True) def save_pkl(hdh_graph, out_base: Path): p = out_base.with_suffix(\".pkl\") with open(p, \"wb\") as f: pickle.dump(hdh_graph, f) return p def save_nodes_csv(hdh_graph, out_path: Path): with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([\"node_id\", \"type\", \"time\", \"realisation\"]) for nid in sorted(hdh_graph.S): w.writerow([ nid, hdh_graph.sigma.get(nid, \"\"), getattr(hdh_graph, \"time_map\", {}).get(nid, \"\"), hdh_graph.upsilon.get(nid, \"\") ]) def save_edges_csvs(hdh_graph, edges_path: Path, members_path: Path): edges_sorted = sorted(hdh_graph.C, key=lambda e: tuple(sorted(e))) # edges table with open(edges_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([ \"edge_index\", \"type\", \"realisation\", \"gate_name\", \"role\", \"edge_args\", \"edge_metadata\" ]) for idx, e in enumerate(edges_sorted): w.writerow([ idx, hdh_graph.tau.get(e, \"\"), hdh_graph.phi.get(e, \"\"), getattr(hdh_graph, \"gate_name\", {}).get(e, \"\"), getattr(hdh_graph, \"edge_role\", {}).get(e, \"\"), json.dumps(getattr(hdh_graph, \"edge_args\", {}).get(e, None)) if e in getattr(hdh_graph, \"edge_args\", {}) else \"\", json.dumps(getattr(hdh_graph, \"edge_metadata\", {}).get(e, None)) if e in getattr(hdh_graph, \"edge_metadata\", {}) else \"\" ]) # edge_members table with open(members_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([\"edge_index\", \"node_id\"]) for idx, e in enumerate(edges_sorted): for nid in sorted(e): w.writerow([idx, nid]) def main(): ap = argparse.ArgumentParser(description=\"Convert QASM workloads to HDH artifacts\") ap.add_argument(\"--model\", default=\"Circuits\", help=\"Model folder\") ap.add_argument(\"--origin\", default=\"MQTBench\", help=\"Origin folder\") ap.add_argument(\"--limit\", type=int, default=None, help=\"Max files to convert\") ap.add_argument(\"--src-root\", default=None, help=\"Override source root\") args = ap.parse_args() SRC_DIR = Path(args.src_root) if args.src_root else BASE_DIR / \"Database\" / \"Workloads\" / args.model / args.origin DST_ROOT = BASE_DIR / \"Database\" / \"HDHs\" / args.model / args.origin PKL_ROOT = DST_ROOT / \"pkl\" TXT_ROOT = DST_ROOT / \"text\" IMG_ROOT = DST_ROOT / \"images\" if not SRC_DIR.exists(): print(f\"[error] Source directory not found: {SRC_DIR}\") sys.exit(1) for d in (PKL_ROOT, TXT_ROOT, IMG_ROOT): ensure_dir(d) qasm_files = sorted(SRC_DIR.rglob(\"*.qasm\")) if not qasm_files: print(f\"[info] No .qasm files found under {SRC_DIR}\") return if args.limit is not None: qasm_files = qasm_files[:args.limit] ok = fail = 0 with tqdm(total=len(qasm_files), desc=\"Converting QASM \u2192 HDH\", unit=\"file\") as pbar: for qf in qasm_files: rel = qf.relative_to(SRC_DIR) stem = rel.stem pkl_dir = PKL_ROOT / rel.parent txt_dir = TXT_ROOT / rel.parent for d in (pkl_dir, txt_dir): ensure_dir(d) pbar.set_postfix_str(str(rel)) try: hdh_graph = from_qasm(\"file\", str(qf)) save_pkl(hdh_graph, pkl_dir / stem) save_nodes_csv(hdh_graph, txt_dir / f\"{stem}__nodes.csv\") save_edges_csvs(hdh_graph, txt_dir / f\"{stem}__edges.csv\", txt_dir / f\"{stem}__edge_members.csv\") ok += 1 except Exception as e: tqdm.write(f\"[fail] {qf}: {e}\") fail += 1 finally: pbar.update(1) print(f\"[done] Converted: {ok} | Failed: {fail}\") if __name__ == \"__main__\": main() Step 3: Verify & Inspect Please open at least one of the text/*.csv files and load at least one of the pkl/*.pkl objects in Python to verify everything works. import pickle import pandas as pd # Load pickled HDH with open(\"Database/HDHs/Circuits/MQTBench/pkl/qft_8.pkl\", \"rb\") as f: hdh = pickle.load(f) # Load CSV files nodes_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__nodes.csv\") edges_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__edges.csv\") members_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__edge_members.csv\") Step 4: Submit a PR If all went smoothly, submit a PR with your workloads and HDHs back to the database-branch . Note : Database files might be too large to directly upload. Use Git LFS : macOS: brew install git-lfs git lfs install Debian/Ubuntu: sudo apt-get update sudo apt-get install git-lfs git lfs install Windows: winget install Git.GitLFS git lfs install From repo root: git lfs track \"*.csv\" git lfs track \"*.pkl\" git add .gitattributes git commit -m \"Adding <Origin> HDHs to database\" git push -u origin database-branch 2) Add Partitioning Method Results If you want to share partitioning method results , add them to: Database/HDHs/<Model>/<Origin>/Partitions/partitions_all.csv CSV Format for Partitioning Results The partitions_all.csv file tracks performance metrics across different partitioning methods. Mandatory Columns file : Name of the origin file n_qubits : Number of qubits in workload k_partitions : Number of partitions (e.g., 2 if cut once) <method>_bins : Sets of qubits per partition (JSON format) <method>_cost : Quantum communication cost (number of quantum hyperedges cut) best : Name of the method with the lowest cost Optional Columns (Method-Specific) <method>_cost_q : Quantum cut cost (if separating q/c) <method>_cost_c : Classical cut cost <method>_partition_sizes : List of partition sizes <method>_avg_parallelism : Average parallelism metric <method>_fairness_ratio : Fairness ratio from fair_parallelism <method>_fails : Boolean indicating if method failed capacity constraints <method>_method : Sub-method used (e.g., for METIS: 'kl', 'recursive') contributor : GitHub username of the person who added this result Example CSV file,n_qubits,k_partitions,greedy_bins,greedy_cost,metis_bins,metis_cost,metis_fails,metis_method,greedytg_bins,greedytg_cost,best,contributor ae_indep_qiskit_10.qasm,10,2,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q3\"\",\"\"q8\"\"],[\"\"q4\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\",\"\"q9\"\"]]\",30,\"[[\"\"q1\"\",\"\"q3\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q0\"\",\"\"q2\"\",\"\"q4\"\",\"\"q8\"\",\"\"q9\"\"]]\",25,False,kl,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q3\"\",\"\"q9\"\"],[\"\"q4\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\",\"\"q8\"\"]]\",30,metis,alice_researcher ae_indep_qiskit_10.qasm,10,3,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q8\"\"],[\"\"q3\"\",\"\"q4\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q5\"\",\"\"q9\"\"]]\",40,\"[[\"\"q3\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q0\"\",\"\"q2\"\"],[\"\"q1\"\",\"\"q4\"\",\"\"q8\"\",\"\"q9\"\"]]\",32,False,kl,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q9\"\"],[\"\"q3\"\",\"\"q4\"\",\"\"q5\"\",\"\"q6\"\"],[\"\"q7\"\",\"\"q8\"\"]]\",38,metis,alice_researcher Standard Partitioning Methods Here are the standard partitioning methods currently in the database: Greedy (HDH) Partitions directly on the HDH hypergraph where each hyperedge captures one operation's dependency set. We fill bins sequentially: order qubits by heuristic (e.g., incident cut weight, then degree), and place each into the earliest bin that (i) respects the logical-qubit capacity and (ii) gives the smallest marginal cut increase. If nothing fits, open the next bin up to k. Cost : Sum of weights of hyperedges spanning >1 bin (default weight 1 per op; domain weights optional). METIS (Telegate graph) Converts the workload into a telegate qubit-interaction graph (nodes = logical qubits; edge weights = interaction pressure indicating a non-local gate would require a \"telegate\" communication if cut). Uses the METIS library to compute a k-way partition with balance constraints and minimal cut on this graph. Partitions are then re-evaluated on the HDH cost for apples-to-apples comparison. Cost : Re-evaluated on HDH hypergraph cut metric. Greedy-TG (Telegate graph) Same fill-first policy as Greedy (HDH), but decisions are made on the telegate graph. Nodes are qubits; edge weights reflect how costly it is to separate two qubits (expected telegate load). Each qubit goes to the earliest feasible bin that minimizes marginal cut on the telegate graph. Cost : Re-evaluated on HDH hypergraph cut metric. Adding Your Results Step 1: Run Your Partitioning Method from hdh.passes import compute_cut, cost, partition_size, parallelism, fair_parallelism import pickle import csv # Load HDH with open(\"Database/HDHs/Circuits/MQTBench/pkl/qft_8.pkl\", \"rb\") as f: hdh = pickle.load(f) # Run your partitioning method bins, _, _, method_name = your_partitioning_method(hdh, k=3, capacity=3) # Compute metrics cost_q, cost_c = cost(hdh, bins) sizes = partition_size(bins) parallel_metrics = parallelism(hdh, bins) fair_metrics = fair_parallelism(hdh, bins, capacities=[3, 3, 3]) # Prepare data for CSV result = { 'file': 'qft_8.qasm', 'n_qubits': 8, 'k_partitions': 3, 'yourmethod_bins': str(bins), 'yourmethod_cost': cost_q, 'yourmethod_cost_q': cost_q, 'yourmethod_cost_c': cost_c, 'yourmethod_partition_sizes': str(sizes), 'yourmethod_avg_parallelism': parallel_metrics['average_parallelism'], 'yourmethod_fairness_ratio': fair_metrics['fairness_ratio'], 'contributor': 'your_github_username' } Step 2: Update partitions_all.csv Add your results to the existing CSV file: import pandas as pd # Load existing results df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\") # Add your new column(s) if they don't exist # Update or append your row # Recalculate 'best' column df.to_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\", index=False) Step 3: Document Your Method Create or update Database/HDHs/<Model>/<Origin>/Partitions/README.md : # Partitioning Methods for <Origin> ## Your Method Name **Contributor**: your_github_username **Date**: YYYY-MM-DD ### Description Brief description of your partitioning algorithm... ### Parameters - Parameter 1: description - Parameter 2: description ### Implementation Details Link to code or detailed explanation... ### Performance Characteristics - Time complexity: O(...) - Space complexity: O(...) - Works best for: ... Step 4: Capacity Constraints and Failure States Capacity = Total qubits \u00f7 number of partitions (rounded up) If your partitioner cannot respect this capacity: * Log a failure status in a <method>_fails column * Set to True if capacity was violated * Exclude from best evaluation if failed Important : Document in the Partitions README whether your method: * Always respects capacity constraints * May violate constraints (and how failures are handled) * Requires specific capacity settings Step 5: Recalculate Best The best column should identify the method with the lowest quantum cost among methods that: 1. Did not fail capacity constraints (where <method>_fails is False or not present) 2. Successfully completed partitioning # Example: Recalculate best cost_columns = [col for col in df.columns if col.endswith('_cost') and not col.endswith('_cost_c')] methods = [col.replace('_cost', '') for col in cost_columns] def get_best_method(row): valid_methods = [] for method in methods: fails_col = f'{method}_fails' cost_col = f'{method}_cost' # Check if method failed if fails_col in row and row[fails_col] == True: continue # Check if cost is valid if pd.notna(row[cost_col]): valid_methods.append((method, row[cost_col])) if not valid_methods: return None # Return method with minimum cost return min(valid_methods, key=lambda x: x[1])[0] df['best'] = df.apply(get_best_method, axis=1) Step 6: Submit PR Submit a PR to the database-branch with: * Updated partitions_all.csv * Updated or new README.md in the Partitions folder * Your GitHub username in the contributor column Database Usage Guidelines For Benchmarking import pickle import pandas as pd from pathlib import Path # Load all HDHs from an origin origin_path = Path(\"Database/HDHs/Circuits/MQTBench/pkl\") hdhs = {} for pkl_file in origin_path.glob(\"*.pkl\"): with open(pkl_file, \"rb\") as f: hdhs[pkl_file.stem] = pickle.load(f) # Load partitioning results results_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\") # Benchmark your method against existing results for name, hdh in hdhs.items(): your_bins, _, _, _ = your_method(hdh, k=3) your_cost, _ = cost(hdh, your_bins) # Compare with best existing method existing_best = results_df[results_df['file'] == f\"{name}.qasm\"]['best'].values[0] existing_cost = results_df[results_df['file'] == f\"{name}.qasm\"][f\"{existing_best}_cost\"].values[0] print(f\"{name}: Your method: {your_cost}, Best existing: {existing_cost}\") Citation and Acknowledgment When using this database in publications, please cite: * The HDH library * The Munich Quantum Benchmarking Dataset (for MQTBench workloads) * Individual contributors whose partitioning results you use Data License The database is provided under the same license as the HDH library (MIT License). Individual workloads may have their own licenses - check the origin-specific README files. Contributing We welcome contributions! When adding to the database: Use clear, descriptive commit messages Document your methods thoroughly in README files Include your GitHub username as contributor Verify your data loads correctly before submitting Update this documentation if adding new features For questions or discussions, please open an issue on the main repository.","title":"The HDH Database"},{"location":"database/#the-hdh-database","text":"To support reproducible evaluation and training of partitioning strategies, this library includes a database of pre-generated HDHs. We aim for this resource to facilitate benchmarking across diverse workloads and enables the development of learning-based distribution agents. Our goal is to extend the database with performance metrics of partitioning techniques for each workload. This will allow the community to build a data-driven understanding of which hypergraph partitioning methods perform best under different conditions. We encourage users to contribute results from their own partitioning methods when working with this database. Instructions for how to upload results can be found below.","title":"The HDH Database"},{"location":"database/#database-location-and-structure","text":"The database is available in the database-branch of the repository . This separation ensures that users of the main library don't need to download unnecessary files. Important : The database exists only in the repository and is not included in the pip package or wheels . Users who want to use the database for benchmarking should clone the database-branch separately. The database is organized into two main directories: Database/ : Contains the actual database files (HDHs and workloads) Database_generator/ : Contains scripts, converters, and utilities for generating and extending the database","title":"Database Location and Structure"},{"location":"database/#database-directory-structure","text":"Database/ \u251c\u2500\u2500 Workloads/ # Raw workload commands \u2502 \u2514\u2500\u2500 <Model>/ \u2502 \u2514\u2500\u2500 <Origin>/ \u2514\u2500\u2500 HDHs/ # Corresponding Hybrid Dependency Hypergraphs \u2514\u2500\u2500 <Model>/ \u2514\u2500\u2500 <Origin>/ \u251c\u2500\u2500 pkl/ # Pickled HDH objects \u251c\u2500\u2500 text/ # Human-readable CSV files \u251c\u2500\u2500 images/ # (reserved for future visualizations) \u2514\u2500\u2500 Partitions/ # Partitioning method results \u251c\u2500\u2500 partitions_all.csv \u2514\u2500\u2500 README.md where: * Model = computational model (e.g., Circuit, MBQC, QW, QCA) * Origin = source of the workload (e.g., benchmark suite, custom circuit)","title":"Database Directory Structure"},{"location":"database/#database_generator-directory","text":"The Database_generator/ folder contains: * Conversion scripts (QASM \u2192 HDH) * Partitioning evaluation scripts * Utilities for batch processing * Configuration templates The database currently contains: HDHs derived from the Munich Quantum Benchmarking Dataset","title":"Database_generator Directory"},{"location":"database/#file-formats","text":"","title":"File Formats"},{"location":"database/#workloads-directory","text":"QASM files representing the quantum workloads","title":"Workloads Directory"},{"location":"database/#hdhs-directory","text":".pkl : Python-pickled HDH objects for programmatic use .txt / .csv : Human-readable text files with annotated metadata __nodes.csv : Node information (node_id, type, time, realisation) __edges.csv : Edge information (edge_index, type, realisation, gate_name, role, edge_args, edge_metadata) __edge_members.csv : Edge-node relationships (edge_index, node_id)","title":"HDHs Directory"},{"location":"database/#partitions-directory","text":"partitions_all.csv : Partitioning results from various methods README.md : Documentation of partitioning methods used","title":"Partitions Directory"},{"location":"database/#hdh-metadata","text":"Each HDH includes metadata describing: Model type : Which computational model the HDH was generated from Workload origin : Reference to the source workload Hybrid status : Whether the HDH contains both quantum and classical nodes Node count : Total number of nodes in the hypergraph Connectivity degree : Average connectivity of the hypergraph Disconnected subgraphs : Number of disconnected components","title":"HDH Metadata"},{"location":"database/#partitioning-performance-metrics","text":"Thanks to the recent additions in PR #24, the library now provides comprehensive metrics for evaluating partitioning quality. These metrics can be computed and added to the database to build a performance baseline.","title":"Partitioning Performance Metrics"},{"location":"database/#available-metrics-from-hdhpasses","text":"","title":"Available Metrics (from hdh.passes)"},{"location":"database/#1-costhdh_graph-partitions-tuplefloat-float","text":"Returns (cost_q, cost_c) - the quantum and classical cut costs: * cost_q : Number of quantum hyperedges that span multiple partitions * cost_c : Number of classical hyperedges that span multiple partitions This is the primary metric for comparing partitioning methods.","title":"1. cost(hdh_graph, partitions) \u2192 Tuple[float, float]"},{"location":"database/#2-partition_sizepartitions-listint","text":"Returns the size (number of nodes) of each partition. Useful for checking balance constraints.","title":"2. partition_size(partitions) \u2192 List[int]"},{"location":"database/#3-participationhdh_graph-partitions-dictstr-float","text":"Measures temporal participation (which partitions have activity at each timestep). Note : This measures presence, not true computational parallelism. Returns: * max_participation : Peak number of active partitions * average_participation : Mean active partitions per timestep * temporal_efficiency : How well time is utilized * partition_utilization : Average fraction of partitions active * timesteps : Total timesteps * num_partitions : Number of partitions","title":"3. participation(hdh_graph, partitions) \u2192 Dict[str, float]"},{"location":"database/#4-parallelismhdh_graph-partitions-dictstr-float","text":"Measures true parallelism by counting concurrent \u03c4-edges (operations) per timestep. This represents actual computational work that can execute simultaneously. Returns: * max_parallelism : Peak concurrent operations * average_parallelism : Mean operations per timestep * total_operations : Total operation count * timesteps : Total timesteps * num_partitions : Number of partitions","title":"4. parallelism(hdh_graph, partitions) \u2192 Dict[str, float]"},{"location":"database/#5-fair_parallelismhdh_graph-partitions-capacities-dictstr-float","text":"Implements Jean's fairness principle - normalizes parallelism by partition capacity to detect workload imbalances. Returns: * max_fair_parallelism : Peak fair parallelism * average_fair_parallelism : Mean fair parallelism * fairness_ratio : Distribution fairness (1.0 = perfectly fair) * total_operations : Total operation count * timesteps : Total timesteps * num_partitions : Number of partitions","title":"5. fair_parallelism(hdh_graph, partitions, capacities) \u2192 Dict[str, float]"},{"location":"database/#usage-example","text":"from hdh.passes import ( cost, partition_size, participation, parallelism, fair_parallelism ) # After running your partitioning method bins, _, _, _ = your_partitioning_method(hdh_graph, k=3) # Evaluate the partition cost_q, cost_c = cost(hdh_graph, bins) sizes = partition_size(bins) participation_metrics = participation(hdh_graph, bins) parallelism_metrics = parallelism(hdh_graph, bins) fair_metrics = fair_parallelism(hdh_graph, bins, capacities=[10, 10, 10]) print(f\"Quantum cut cost: {cost_q}\") print(f\"Classical cut cost: {cost_c}\") print(f\"Partition sizes: {sizes}\") print(f\"Average parallelism: {parallelism_metrics['average_parallelism']}\") print(f\"Fairness ratio: {fair_metrics['fairness_ratio']}\")","title":"Usage Example"},{"location":"database/#extending-the-dataset","text":"We encourage users to: Add new workloads (QASM or other supported formats ) Generate corresponding HDHs Run partitioning methods and contribute results Propose and document new metrics Pull requests that expand the benchmark set or enrich metadata are very welcome!","title":"Extending the Dataset"},{"location":"database/#how-to-add-to-this-database","text":"There are two ways to contribute:","title":"How to Add to This Database"},{"location":"database/#1-add-new-workloads-hdhs","text":"","title":"1) Add New Workloads + HDHs"},{"location":"database/#step-1-place-workloads","text":"Put your workload origin files under: Database/Workloads/<Model>/<Origin>/ This could be anything from a QASM file to circuit generation code. If the HDH is not generated from functions within the library, we request you add a README.md to your origin folder explaining how the HDHs were generated. Example: Database/Workloads/Circuits/MQTBench/qft_8.qasm","title":"Step 1: Place Workloads"},{"location":"database/#step-2-run-the-converter","text":"Convert the files (QASM strings, Qiskit circuits, etc.) to HDHs. The converter will create: Database/HDHs/<Model>/<Origin>/pkl/<filename>.pkl Database/HDHs/<Model>/<Origin>/text/<filename>__nodes.csv Database/HDHs/<Model>/<Origin>/text/<filename>__edges.csv Database/HDHs/<Model>/<Origin>/text/<filename>__edge_members.csv","title":"Step 2: Run the Converter"},{"location":"database/#converter-script-qasm-hdh-pklcsv","text":"The converter script is available in Database_generator/ folder. Requirements: tqdm, the HDH library available on PYTHONPATH, and your QASM converter ( hdh.converters.from_qasm ). #!/usr/bin/env python3 import sys import os import csv import json import pickle from pathlib import Path from tqdm import tqdm import argparse # Repo import path (adjust as needed) sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) from hdh.converters import from_qasm BASE_DIR = Path(__file__).resolve().parent def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True) def save_pkl(hdh_graph, out_base: Path): p = out_base.with_suffix(\".pkl\") with open(p, \"wb\") as f: pickle.dump(hdh_graph, f) return p def save_nodes_csv(hdh_graph, out_path: Path): with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([\"node_id\", \"type\", \"time\", \"realisation\"]) for nid in sorted(hdh_graph.S): w.writerow([ nid, hdh_graph.sigma.get(nid, \"\"), getattr(hdh_graph, \"time_map\", {}).get(nid, \"\"), hdh_graph.upsilon.get(nid, \"\") ]) def save_edges_csvs(hdh_graph, edges_path: Path, members_path: Path): edges_sorted = sorted(hdh_graph.C, key=lambda e: tuple(sorted(e))) # edges table with open(edges_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([ \"edge_index\", \"type\", \"realisation\", \"gate_name\", \"role\", \"edge_args\", \"edge_metadata\" ]) for idx, e in enumerate(edges_sorted): w.writerow([ idx, hdh_graph.tau.get(e, \"\"), hdh_graph.phi.get(e, \"\"), getattr(hdh_graph, \"gate_name\", {}).get(e, \"\"), getattr(hdh_graph, \"edge_role\", {}).get(e, \"\"), json.dumps(getattr(hdh_graph, \"edge_args\", {}).get(e, None)) if e in getattr(hdh_graph, \"edge_args\", {}) else \"\", json.dumps(getattr(hdh_graph, \"edge_metadata\", {}).get(e, None)) if e in getattr(hdh_graph, \"edge_metadata\", {}) else \"\" ]) # edge_members table with open(members_path, \"w\", newline=\"\", encoding=\"utf-8\") as f: w = csv.writer(f) w.writerow([\"edge_index\", \"node_id\"]) for idx, e in enumerate(edges_sorted): for nid in sorted(e): w.writerow([idx, nid]) def main(): ap = argparse.ArgumentParser(description=\"Convert QASM workloads to HDH artifacts\") ap.add_argument(\"--model\", default=\"Circuits\", help=\"Model folder\") ap.add_argument(\"--origin\", default=\"MQTBench\", help=\"Origin folder\") ap.add_argument(\"--limit\", type=int, default=None, help=\"Max files to convert\") ap.add_argument(\"--src-root\", default=None, help=\"Override source root\") args = ap.parse_args() SRC_DIR = Path(args.src_root) if args.src_root else BASE_DIR / \"Database\" / \"Workloads\" / args.model / args.origin DST_ROOT = BASE_DIR / \"Database\" / \"HDHs\" / args.model / args.origin PKL_ROOT = DST_ROOT / \"pkl\" TXT_ROOT = DST_ROOT / \"text\" IMG_ROOT = DST_ROOT / \"images\" if not SRC_DIR.exists(): print(f\"[error] Source directory not found: {SRC_DIR}\") sys.exit(1) for d in (PKL_ROOT, TXT_ROOT, IMG_ROOT): ensure_dir(d) qasm_files = sorted(SRC_DIR.rglob(\"*.qasm\")) if not qasm_files: print(f\"[info] No .qasm files found under {SRC_DIR}\") return if args.limit is not None: qasm_files = qasm_files[:args.limit] ok = fail = 0 with tqdm(total=len(qasm_files), desc=\"Converting QASM \u2192 HDH\", unit=\"file\") as pbar: for qf in qasm_files: rel = qf.relative_to(SRC_DIR) stem = rel.stem pkl_dir = PKL_ROOT / rel.parent txt_dir = TXT_ROOT / rel.parent for d in (pkl_dir, txt_dir): ensure_dir(d) pbar.set_postfix_str(str(rel)) try: hdh_graph = from_qasm(\"file\", str(qf)) save_pkl(hdh_graph, pkl_dir / stem) save_nodes_csv(hdh_graph, txt_dir / f\"{stem}__nodes.csv\") save_edges_csvs(hdh_graph, txt_dir / f\"{stem}__edges.csv\", txt_dir / f\"{stem}__edge_members.csv\") ok += 1 except Exception as e: tqdm.write(f\"[fail] {qf}: {e}\") fail += 1 finally: pbar.update(1) print(f\"[done] Converted: {ok} | Failed: {fail}\") if __name__ == \"__main__\": main()","title":"Converter Script (QASM \u2192 HDH \u2192 {pkl,csv})"},{"location":"database/#step-3-verify-inspect","text":"Please open at least one of the text/*.csv files and load at least one of the pkl/*.pkl objects in Python to verify everything works. import pickle import pandas as pd # Load pickled HDH with open(\"Database/HDHs/Circuits/MQTBench/pkl/qft_8.pkl\", \"rb\") as f: hdh = pickle.load(f) # Load CSV files nodes_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__nodes.csv\") edges_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__edges.csv\") members_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/text/qft_8__edge_members.csv\")","title":"Step 3: Verify &amp; Inspect"},{"location":"database/#step-4-submit-a-pr","text":"If all went smoothly, submit a PR with your workloads and HDHs back to the database-branch . Note : Database files might be too large to directly upload. Use Git LFS : macOS: brew install git-lfs git lfs install Debian/Ubuntu: sudo apt-get update sudo apt-get install git-lfs git lfs install Windows: winget install Git.GitLFS git lfs install From repo root: git lfs track \"*.csv\" git lfs track \"*.pkl\" git add .gitattributes git commit -m \"Adding <Origin> HDHs to database\" git push -u origin database-branch","title":"Step 4: Submit a PR"},{"location":"database/#2-add-partitioning-method-results","text":"If you want to share partitioning method results , add them to: Database/HDHs/<Model>/<Origin>/Partitions/partitions_all.csv","title":"2) Add Partitioning Method Results"},{"location":"database/#csv-format-for-partitioning-results","text":"The partitions_all.csv file tracks performance metrics across different partitioning methods.","title":"CSV Format for Partitioning Results"},{"location":"database/#mandatory-columns","text":"file : Name of the origin file n_qubits : Number of qubits in workload k_partitions : Number of partitions (e.g., 2 if cut once) <method>_bins : Sets of qubits per partition (JSON format) <method>_cost : Quantum communication cost (number of quantum hyperedges cut) best : Name of the method with the lowest cost","title":"Mandatory Columns"},{"location":"database/#optional-columns-method-specific","text":"<method>_cost_q : Quantum cut cost (if separating q/c) <method>_cost_c : Classical cut cost <method>_partition_sizes : List of partition sizes <method>_avg_parallelism : Average parallelism metric <method>_fairness_ratio : Fairness ratio from fair_parallelism <method>_fails : Boolean indicating if method failed capacity constraints <method>_method : Sub-method used (e.g., for METIS: 'kl', 'recursive') contributor : GitHub username of the person who added this result","title":"Optional Columns (Method-Specific)"},{"location":"database/#example-csv","text":"file,n_qubits,k_partitions,greedy_bins,greedy_cost,metis_bins,metis_cost,metis_fails,metis_method,greedytg_bins,greedytg_cost,best,contributor ae_indep_qiskit_10.qasm,10,2,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q3\"\",\"\"q8\"\"],[\"\"q4\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\",\"\"q9\"\"]]\",30,\"[[\"\"q1\"\",\"\"q3\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q0\"\",\"\"q2\"\",\"\"q4\"\",\"\"q8\"\",\"\"q9\"\"]]\",25,False,kl,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q3\"\",\"\"q9\"\"],[\"\"q4\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\",\"\"q8\"\"]]\",30,metis,alice_researcher ae_indep_qiskit_10.qasm,10,3,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q8\"\"],[\"\"q3\"\",\"\"q4\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q5\"\",\"\"q9\"\"]]\",40,\"[[\"\"q3\"\",\"\"q5\"\",\"\"q6\"\",\"\"q7\"\"],[\"\"q0\"\",\"\"q2\"\"],[\"\"q1\"\",\"\"q4\"\",\"\"q8\"\",\"\"q9\"\"]]\",32,False,kl,\"[[\"\"q0\"\",\"\"q1\"\",\"\"q2\"\",\"\"q9\"\"],[\"\"q3\"\",\"\"q4\"\",\"\"q5\"\",\"\"q6\"\"],[\"\"q7\"\",\"\"q8\"\"]]\",38,metis,alice_researcher","title":"Example CSV"},{"location":"database/#standard-partitioning-methods","text":"Here are the standard partitioning methods currently in the database:","title":"Standard Partitioning Methods"},{"location":"database/#greedy-hdh","text":"Partitions directly on the HDH hypergraph where each hyperedge captures one operation's dependency set. We fill bins sequentially: order qubits by heuristic (e.g., incident cut weight, then degree), and place each into the earliest bin that (i) respects the logical-qubit capacity and (ii) gives the smallest marginal cut increase. If nothing fits, open the next bin up to k. Cost : Sum of weights of hyperedges spanning >1 bin (default weight 1 per op; domain weights optional).","title":"Greedy (HDH)"},{"location":"database/#metis-telegate-graph","text":"Converts the workload into a telegate qubit-interaction graph (nodes = logical qubits; edge weights = interaction pressure indicating a non-local gate would require a \"telegate\" communication if cut). Uses the METIS library to compute a k-way partition with balance constraints and minimal cut on this graph. Partitions are then re-evaluated on the HDH cost for apples-to-apples comparison. Cost : Re-evaluated on HDH hypergraph cut metric.","title":"METIS (Telegate graph)"},{"location":"database/#greedy-tg-telegate-graph","text":"Same fill-first policy as Greedy (HDH), but decisions are made on the telegate graph. Nodes are qubits; edge weights reflect how costly it is to separate two qubits (expected telegate load). Each qubit goes to the earliest feasible bin that minimizes marginal cut on the telegate graph. Cost : Re-evaluated on HDH hypergraph cut metric.","title":"Greedy-TG (Telegate graph)"},{"location":"database/#adding-your-results","text":"","title":"Adding Your Results"},{"location":"database/#step-1-run-your-partitioning-method","text":"from hdh.passes import compute_cut, cost, partition_size, parallelism, fair_parallelism import pickle import csv # Load HDH with open(\"Database/HDHs/Circuits/MQTBench/pkl/qft_8.pkl\", \"rb\") as f: hdh = pickle.load(f) # Run your partitioning method bins, _, _, method_name = your_partitioning_method(hdh, k=3, capacity=3) # Compute metrics cost_q, cost_c = cost(hdh, bins) sizes = partition_size(bins) parallel_metrics = parallelism(hdh, bins) fair_metrics = fair_parallelism(hdh, bins, capacities=[3, 3, 3]) # Prepare data for CSV result = { 'file': 'qft_8.qasm', 'n_qubits': 8, 'k_partitions': 3, 'yourmethod_bins': str(bins), 'yourmethod_cost': cost_q, 'yourmethod_cost_q': cost_q, 'yourmethod_cost_c': cost_c, 'yourmethod_partition_sizes': str(sizes), 'yourmethod_avg_parallelism': parallel_metrics['average_parallelism'], 'yourmethod_fairness_ratio': fair_metrics['fairness_ratio'], 'contributor': 'your_github_username' }","title":"Step 1: Run Your Partitioning Method"},{"location":"database/#step-2-update-partitions_allcsv","text":"Add your results to the existing CSV file: import pandas as pd # Load existing results df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\") # Add your new column(s) if they don't exist # Update or append your row # Recalculate 'best' column df.to_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\", index=False)","title":"Step 2: Update partitions_all.csv"},{"location":"database/#step-3-document-your-method","text":"Create or update Database/HDHs/<Model>/<Origin>/Partitions/README.md : # Partitioning Methods for <Origin> ## Your Method Name **Contributor**: your_github_username **Date**: YYYY-MM-DD ### Description Brief description of your partitioning algorithm... ### Parameters - Parameter 1: description - Parameter 2: description ### Implementation Details Link to code or detailed explanation... ### Performance Characteristics - Time complexity: O(...) - Space complexity: O(...) - Works best for: ...","title":"Step 3: Document Your Method"},{"location":"database/#step-4-capacity-constraints-and-failure-states","text":"Capacity = Total qubits \u00f7 number of partitions (rounded up) If your partitioner cannot respect this capacity: * Log a failure status in a <method>_fails column * Set to True if capacity was violated * Exclude from best evaluation if failed Important : Document in the Partitions README whether your method: * Always respects capacity constraints * May violate constraints (and how failures are handled) * Requires specific capacity settings","title":"Step 4: Capacity Constraints and Failure States"},{"location":"database/#step-5-recalculate-best","text":"The best column should identify the method with the lowest quantum cost among methods that: 1. Did not fail capacity constraints (where <method>_fails is False or not present) 2. Successfully completed partitioning # Example: Recalculate best cost_columns = [col for col in df.columns if col.endswith('_cost') and not col.endswith('_cost_c')] methods = [col.replace('_cost', '') for col in cost_columns] def get_best_method(row): valid_methods = [] for method in methods: fails_col = f'{method}_fails' cost_col = f'{method}_cost' # Check if method failed if fails_col in row and row[fails_col] == True: continue # Check if cost is valid if pd.notna(row[cost_col]): valid_methods.append((method, row[cost_col])) if not valid_methods: return None # Return method with minimum cost return min(valid_methods, key=lambda x: x[1])[0] df['best'] = df.apply(get_best_method, axis=1)","title":"Step 5: Recalculate Best"},{"location":"database/#step-6-submit-pr","text":"Submit a PR to the database-branch with: * Updated partitions_all.csv * Updated or new README.md in the Partitions folder * Your GitHub username in the contributor column","title":"Step 6: Submit PR"},{"location":"database/#database-usage-guidelines","text":"","title":"Database Usage Guidelines"},{"location":"database/#for-benchmarking","text":"import pickle import pandas as pd from pathlib import Path # Load all HDHs from an origin origin_path = Path(\"Database/HDHs/Circuits/MQTBench/pkl\") hdhs = {} for pkl_file in origin_path.glob(\"*.pkl\"): with open(pkl_file, \"rb\") as f: hdhs[pkl_file.stem] = pickle.load(f) # Load partitioning results results_df = pd.read_csv(\"Database/HDHs/Circuits/MQTBench/Partitions/partitions_all.csv\") # Benchmark your method against existing results for name, hdh in hdhs.items(): your_bins, _, _, _ = your_method(hdh, k=3) your_cost, _ = cost(hdh, your_bins) # Compare with best existing method existing_best = results_df[results_df['file'] == f\"{name}.qasm\"]['best'].values[0] existing_cost = results_df[results_df['file'] == f\"{name}.qasm\"][f\"{existing_best}_cost\"].values[0] print(f\"{name}: Your method: {your_cost}, Best existing: {existing_cost}\")","title":"For Benchmarking"},{"location":"database/#citation-and-acknowledgment","text":"When using this database in publications, please cite: * The HDH library * The Munich Quantum Benchmarking Dataset (for MQTBench workloads) * Individual contributors whose partitioning results you use","title":"Citation and Acknowledgment"},{"location":"database/#data-license","text":"The database is provided under the same license as the HDH library (MIT License). Individual workloads may have their own licenses - check the origin-specific README files.","title":"Data License"},{"location":"database/#contributing","text":"We welcome contributions! When adding to the database: Use clear, descriptive commit messages Document your methods thoroughly in README files Include your GitHub username as contributor Verify your data loads correctly before submitting Update this documentation if adding new features For questions or discussions, please open an issue on the main repository.","title":"Contributing"},{"location":"hdh/","text":"Hybrid Dependency Hypergraphs HDHs are a special type of directed hypergraphs designed to encode temporal and spatial dependencies of quantum computations with the purpose of distributing originally monolothic quantum or hybrid workloads. Hypergraph abstractions are currently the standard approach for partitioning quantum computations in distributed quantum computing, [ 1 ]. HDHs extend this practice by providing a consistent and complete representation framework, intended to support the systematic evaluation and comparison of partitioning strategies. A hypergraph consists of a set of nodes and a family of subsets of these nodes, called hyperedges[ 2 ]. In HDHs these hyperedges can be refered to as connections, as they represent the connectivity requirements between nodes. Meaning that if a HDH is partitioned, the operations represented as inter-partition hyperedges would need to be replaced by equivalent communication primitives (such as a non-local gate or a teleportation protocol). Hypergraphs are made up of nodes and hyperedges that can either be quantum or classical (representing qubits or bits/cbits) and realised or potential . These types q/c and r/a enable the representation of any quantum of hybrid computation. When visualized they will be reprented by these symbols: Quantum operations may give rise to single-type operations, for instance a single qubit gate in the circuit model would give rise a quantum node and hyperedge, or two multi-type operations: the initialization of a qubit based on a previous measurement reading would lead to a classical node and a quantum node. The r/a types are useful for representing instructions that may \"potentially\" happen given previous results, such as IfElse operations found in dynamic circuits.","title":"A brief introduction to HDHs"},{"location":"hdh/#hybrid-dependency-hypergraphs","text":"HDHs are a special type of directed hypergraphs designed to encode temporal and spatial dependencies of quantum computations with the purpose of distributing originally monolothic quantum or hybrid workloads. Hypergraph abstractions are currently the standard approach for partitioning quantum computations in distributed quantum computing, [ 1 ]. HDHs extend this practice by providing a consistent and complete representation framework, intended to support the systematic evaluation and comparison of partitioning strategies. A hypergraph consists of a set of nodes and a family of subsets of these nodes, called hyperedges[ 2 ]. In HDHs these hyperedges can be refered to as connections, as they represent the connectivity requirements between nodes. Meaning that if a HDH is partitioned, the operations represented as inter-partition hyperedges would need to be replaced by equivalent communication primitives (such as a non-local gate or a teleportation protocol). Hypergraphs are made up of nodes and hyperedges that can either be quantum or classical (representing qubits or bits/cbits) and realised or potential . These types q/c and r/a enable the representation of any quantum of hybrid computation. When visualized they will be reprented by these symbols: Quantum operations may give rise to single-type operations, for instance a single qubit gate in the circuit model would give rise a quantum node and hyperedge, or two multi-type operations: the initialization of a qubit based on a previous measurement reading would lead to a classical node and a quantum node. The r/a types are useful for representing instructions that may \"potentially\" happen given previous results, such as IfElse operations found in dynamic circuits.","title":"Hybrid Dependency Hypergraphs"},{"location":"intro/","text":"An introduction to Distributed Quantum Computing The main problem behind distributed quantum computing is how to map quantum workloads to a network of quantum devices. Unlike its classical counterpart, the so-called mapping problem must account for both classical and quantum data and operations within the workload, as well as quantum and classical devices and connections within the network. Two main strategies have arisem in this context: Bespoke algorithm design: splitting the workload into smaller sub-workloads defined by algorithmic tasks (as in distributed versions of Shor\u2019s and Grover\u2019s algorithms) or by subproblems (something more along the lines of partitioning a large Hamiltonian into sub-Hamiltonians and communication terms [ 1 ]). Hypergraph abstractions: abstracting a quantum circuit into a hypergraph to then partition it with max-cut heuristics [ 2 ], replacing every cut hyperedge with an equivalent communication primitive (a non-local gate when partitioning through a gate, or a teleportation protocol when partitioning through a wire). This library contributes to the second strategy, which unlike bespoke algorithmic designs, does not require knowledge of the problem structure or algorithmic logic, and can be applied to any compiled quantum program. In this context the mapping problem can be defined as: Even in a simplified setting where only communication minimization is considered, the network mapping problem is computationally intractable. In particular, the decision version of the problem is NP-hard, even for a fixed network topology of only two nodes with equal capacity, where the objective reduces to partitioning V_C into two equal-sized sets while minimizing the number of hyperedges crossing between them. This case is equivalent to the sparsest cut problem with unit capacities, which is NP-hard via a reduction from the max-cut problem [ 3 ]. Our best strategy, therefore, is to design fast and efficient heuristic partitioners. State-of-the-art partitioning strategies include Fiduccia\u2013Mattheyses and multilevel partitioners (such as KaHyPar ). We recommend this review if you want to learn more about how these strategies have been applied to circuit partitioning. Nonetheless, a few bottlenecks remain, making cross-partitioning method comparison difficult. For a start, hypergraphs built for abstracting quantum workloads can be constructed using different conventions, for example, mapping qubits to nodes and multi-qubit gates to hyperedges, or vice versa. These are known as telegate and teledata. This variety of representations has led to inconsistencies that complicate direct comparisons between partitioning methods for distributed quantum circuits. To address this, strategies that can utilize both abstractions have been proposed [ 4 , 5 ], but not an easy-to-use unifying abstraction. Beyond telegate and teledata, restricting to the circuit model also imposes a significant limitation. Photons, the most practical medium for long-range quantum communication\u2014are used in photonic quantum computers that do not operate under the circuit model. As a result, current compiler distribution frameworks are incompatible with key hardware platforms needed for near-term distributed quantum computing testbeds. They exclude alternative computational models required by some quantum devices and cannot accommodate hybrid quantum\u2013classical workloads. HDHs address both challenges and provide a unifying abstraction for representing partitioning across all models. This library is designed to make HDHs easy to construct and to offer a database where state-of-the-art and future techniques can be benchmarked against each other in one common framework. For a concise overview of how HDHs are built, see our brief introduction to HDHs .","title":"An introduction to DQC"},{"location":"intro/#an-introduction-to-distributed-quantum-computing","text":"The main problem behind distributed quantum computing is how to map quantum workloads to a network of quantum devices. Unlike its classical counterpart, the so-called mapping problem must account for both classical and quantum data and operations within the workload, as well as quantum and classical devices and connections within the network. Two main strategies have arisem in this context: Bespoke algorithm design: splitting the workload into smaller sub-workloads defined by algorithmic tasks (as in distributed versions of Shor\u2019s and Grover\u2019s algorithms) or by subproblems (something more along the lines of partitioning a large Hamiltonian into sub-Hamiltonians and communication terms [ 1 ]). Hypergraph abstractions: abstracting a quantum circuit into a hypergraph to then partition it with max-cut heuristics [ 2 ], replacing every cut hyperedge with an equivalent communication primitive (a non-local gate when partitioning through a gate, or a teleportation protocol when partitioning through a wire). This library contributes to the second strategy, which unlike bespoke algorithmic designs, does not require knowledge of the problem structure or algorithmic logic, and can be applied to any compiled quantum program. In this context the mapping problem can be defined as: Even in a simplified setting where only communication minimization is considered, the network mapping problem is computationally intractable. In particular, the decision version of the problem is NP-hard, even for a fixed network topology of only two nodes with equal capacity, where the objective reduces to partitioning V_C into two equal-sized sets while minimizing the number of hyperedges crossing between them. This case is equivalent to the sparsest cut problem with unit capacities, which is NP-hard via a reduction from the max-cut problem [ 3 ]. Our best strategy, therefore, is to design fast and efficient heuristic partitioners. State-of-the-art partitioning strategies include Fiduccia\u2013Mattheyses and multilevel partitioners (such as KaHyPar ). We recommend this review if you want to learn more about how these strategies have been applied to circuit partitioning. Nonetheless, a few bottlenecks remain, making cross-partitioning method comparison difficult. For a start, hypergraphs built for abstracting quantum workloads can be constructed using different conventions, for example, mapping qubits to nodes and multi-qubit gates to hyperedges, or vice versa. These are known as telegate and teledata. This variety of representations has led to inconsistencies that complicate direct comparisons between partitioning methods for distributed quantum circuits. To address this, strategies that can utilize both abstractions have been proposed [ 4 , 5 ], but not an easy-to-use unifying abstraction. Beyond telegate and teledata, restricting to the circuit model also imposes a significant limitation. Photons, the most practical medium for long-range quantum communication\u2014are used in photonic quantum computers that do not operate under the circuit model. As a result, current compiler distribution frameworks are incompatible with key hardware platforms needed for near-term distributed quantum computing testbeds. They exclude alternative computational models required by some quantum devices and cannot accommodate hybrid quantum\u2013classical workloads. HDHs address both challenges and provide a unifying abstraction for representing partitioning across all models. This library is designed to make HDHs easy to construct and to offer a database where state-of-the-art and future techniques can be benchmarked against each other in one common framework. For a concise overview of how HDHs are built, see our brief introduction to HDHs .","title":"An introduction to Distributed Quantum Computing"},{"location":"literature/","text":"HDHs and associated projects have been presented at the following conferences : SIGCOMM25 POSTER: Distributed Quantum Computing Across Heterogeneous Hardware with Hybrid Dependency Hypergraphs Extended Abstract Poster IWQC25 : Hybrid Dependency Hypergraphs: A model agnostic IR for distributed quantum computing at the compilation level","title":"Related publications and information"},{"location":"models/","text":"Computational models Quantum computation can be performed with various computational models that have different instruction sets, such as quantum circuits (which perform computation through gates) or measurement based patterns (which perform computation through corrections). The diversity between these models can be attributed to hardware constraints as well as to the age of the field. Although they are all equivalent and computations can theoretically be translated accross them, this process is inneficient and hard to due to a lack of clear set of cross-model translators. HDHs were designed to abstract all the models into a unified framework. As such, they are model agnostic and can be constructed from any set of instructions. Specific model classes can be found under the hdh/models folder. To facilitate the usage of HDHs, the library has a set of embedded model mappings which translate instruction sets from popular quantum computational models into reusable HDH motifs. You can find details and examples of how to use these model classes and SDK converters bellow. Circuits The circuit model is among the most widely adopted paradigms of quantum computation, particularly in implementations on industrial quantum hardware (with the notable exception of photonic qubits). Quantum circuits are a universal model of computation. They form the foundation of many leading quantum software packages, including Qiskit , OpenQASM , Cirq , Amazon Braket SDK , and PennyLane ; which you can directly map to the librarys' Circuit class and then to HDHs (see examples of how to use these converters bellow). A quantum circuit is composed of a sequence of quantum gates applied to a set of qubits (commonly represented as horizontal wires). Gates, visualized as boxes placed on these wires, may act on one or multiple qubits. Single-qubit gates correspond to rotations of the qubit\u2019s state vector on the Bloch sphere. For example, a Z-rotation by angle \u03c0 rotates the state vector by \u03c0 radians about the z-axis. Multi-qubit gates, such as controlled-X (CX), act conditionally on one qubit\u2019s state and thereby create dependencies among qubits. For instance, a CX gate applies an X gate to the target qubit only if the control qubit is in the \u22231\u27e9 state. Such gates generate entanglement, as discussed in the introduction to DQC . Beyond static gates, circuits also support classically conditioned operations. For example, an IfElse construct applies one subcircuit if a specified classical register holds a given value and another subcircuit otherwise. This enables hybrid quantum\u2013classical flow control within circuits. Finally, measurement operations project qubits into classical bits, irreversibly collapsing their quantum state. The goal of HDHs is to make explicit the transformations induced by all gates and measurements, enabling large circuits to be partitioned into smaller, distributable subcircuits. Mapping a quantum circuit into an HDH involves applying the correspondences summarized in the table below: Bellow is an example of how to build a circuit using the library\u2019s Circuit class and map it to an HDH: import hdh from hdh.models.circuit import Circuit from hdh.visualize import plot_hdh circuit = Circuit() # Set of instructions circuit.add_instruction(\"ccx\", [0, 1, 2]) circuit.add_instruction(\"h\", [3]) circuit.add_instruction(\"h\", [5]) circuit.add_instruction(\"cx\", [3, 4]) circuit.add_instruction(\"cx\", [2, 1]) # NOTE: The example with the line bellow uncommented will be added soon # circuit.add_conditional_gate(5, 4, \"z\") circuit.add_instruction(\"cx\", [0, 3]) circuit.add_instruction(\"measure\", [2]) circuit.add_instruction(\"measure\", [4]) hdh = circuit.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code is equivalent to the following circuit: Which is mapped to HDH: The HDH is composed of the motifs shown in the mapping table, appearing in the temporal order of computation and indexed by the qubits they abstract. Note that a qubit is not initialized until the timestep immediately preceding its first operation. MBQC patterns Measurement based quantum computing is one of the alternative universal models to quantum circuits [ 3 ]. It can be implemented on photonic quantum computers, as is often paired alongside fusion gates [ 4 ]. MBQC patterns consist of 4 types of operations [ 5 ]: N: Auxiliary state preparations E: Entaglement operations M: Measurements C: Corrections Intuitively, MBQC patterns can be thought of as large cluster states built from entangled nodes. The computation proceeds by measuring these nodes in sequence, where later measurement bases are adapted according to the outcomes of earlier ones. Measurement based patterns may look like this (taken from 6 ): . Here the N operations form the nodes, and E operations make the Edges. Time flows from left to right; and the angles (0, \u03c0/8) correspond to correction angles. Equivalences between circuit gates and MBQC patterns can be drawn (in this case squares = output qubits) [ 6 ]: But they are not necessarily the most efficient use of the model. Many MBQC native algorithms have been proposed [ 7 , 8 ], and the model is very compatible with various error correction techniques. If you'd like a more in depth tutorial on the model we recommend this pennylane tutorial on MBQC . Distribution of MBQC patterns can be confused with the partitioning of the substrate cluster state over which they are computed (the network you see). This is a valid method for partitioning the computation, but it is not the one that HDHs offer. As in the circuit model, HDHs abstract the operations performed during the computation (atop the cluster or during cluster generation) in a way that reflects not only their entanglement dependencies but also their temporal dependencies (aka the order in which they are performed). Mapping MBQC patterns to HDHs is relatively simple: import hdh from hdh.models.mbqc import MBQC from hdh.visualize import plot_hdh mbqc = MBQC() # Set of instructions mbqc.add_operation(\"N\", [], \"q0\") mbqc.add_operation(\"N\", [], \"q1\") mbqc.add_operation(\"E\", [\"q0\", \"q1\"], \"q1\") mbqc.add_operation(\"M\", [\"q0\"], \"c0\") mbqc.add_operation(\"C\", [\"c0\"], \"q2\") hdh = mbqc.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: Unlike in the circuit model, MBQC pattern operations are not \"automatically\" assigned to the q_ and c_ naming conventions. This is because a node in an MBQC pattern doesn't necessarily directly correspond to a qubit. For simplicity we have made it so in the example above, but feel free to name them something else. Note that if you do the visualize function may play some tricks on you depending on the version of the library you are working with. This is the corresponding motif to operation mapping table for the MBQC model: Quantum walks Quantum walks are another universal model of quantum computation [ 9 ]. Like quantum circuits, quantum walks can be expressed using different sets of unitary operations and are universal for quantum computation. However, unlike circuits, quantum walks are not inherently defined in terms of gate sequences, they are abstract evolution models that can be implemented via gates or analog dynamics depending on the platform. They come in various forms, typically categorized as discrete-time or continuous-time variants [ 10 ]. In discrete-time walks (DTQW), evolution proceeds in steps using a coin operator and a shift operator; while continuous-time walks (CTQW) evolve directly under a Hamiltonian. In both cases, the key idea is that the walker\u2019s amplitude spreads across positions in superposition, creating interference patterns that can be harnessed for computation. This interference, guided by the chosen coin or Hamiltonian, allows quantum walks to implement algorithms and decision processes that outperform their classical counterparts. Unlike classical random walks, where probabilities govern independent step outcomes, quantum walks evolve coherently under unitary dynamics, so amplitudes rather than probabilities interfere. Perhaps a useful visualisation of this is to view quantum walks as waves spreading across all paths simultaneously, as per the image bellow (taken from [ 11 ]), where the two peaks of the amplitude distribution at the final row can be seen at the edges, in contrast to the central Gaussian-like spread (red) of the classical walk: The reason why the distributions are different is that in a classical walk, each step is an independent random choice. Adding them up gives a binomial distribution, which converges to a Gaussian around the center. In a quantum walk, the walker is in a superposition of paths. At each step, amplitudes for moving left or right interfere. Constructive interference pushes weight toward the outer edges, while destructive interference cancels amplitudes near the center. As a result, the probability distribution spreads ballistically (linearly with the number of steps) rather than diffusively (square root of steps), and peaks form at the farthest positions the walker can reach. You can map QW to HDHs as per: import hdh from hdh.models.qw import QW from hdh.visualize import plot_hdh qw = QW(type=discrete) # Set of instructions q0 = \"q0\" q1 = qw.add_coin(q0) q2 = qw.add_shift(q1) qw.add_measurement(q2, \"c0\") hdh = qw.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: This is the corresponding motif to operation mapping table for the QW model: Bellow you can find a short explanation explaining the differences between DTQW and CTQW implementations. If you're interested in QW, we recommend this book . Discrete Time Quantum Walks A DTQW is made up of a set of timed operations imposed by its coin and walker. If we where to equate this to the NEMC format for MBQC, DTQW operations would be of two types: Coin: local unitaries acting on internal degrees of freedom at each position, e.g., internal \"spin\" or coin states, Shift: conditional displacements of walker states in position space based on the coin state. The outputs of each coin toss serve as inputs to the subsequent shift. A DTQW is \"valid\" if all operations can be sequentially ordered. Their mapping to HDHs is straightforward: inputs and outputs align naturally with state nodes, while coin and shift operations correspond to channel hyperedges. In practice, each coin operation introduces a local unitary hyperedge attached to the state node representing the walker\u2019s internal degree of freedom at a given time. Each shift operation then acts as a conditional hyperedge spanning the relevant position nodes, effectively redirecting walker states according to the coin outcome. Because HDHs are time-respecting, the sequential interplay of coin and shift steps is preserved explicitly, making the walk\u2019s evolution appear as an alternating pattern of local and conditional hyperedges across timesteps. Continuous Time Quantum Walks In contrast, CTQWs describe physical evolution over time under a Hamiltonian and do not, by themselves, constitute a universal computational model. They lack a well-defined, manipulable set of time-indexed operations. Nonetheless, CTQWs can still be mapped to HDH constructions by interpreting their continuous evolution as a resource-driven process. HDHs accommodate this by using dedicated predictive constructs to represent these operations. In other words they discretize the CTQW, and map it using the DTQW mapping, whilst setting each operation to the predicted type. This logic can be extended to other prominent quantum frameworks, such as adiabatic quantum computing, which likewise lack native representations of sequential logical operations but can still be encoded into HDHs by discretizing their dynamics and treating them as structured evolution patterns. Quantum cellular automata Finally, the last model currently compatible with the HDH library is QCA (Quantum cellular automaton). QCAs originally arose as an alternative paradigm for quantum computation, though more recently they have found application in understanding topological phases of matter and have been proposed as models of periodically driven (Floquet) quantum systems [ 12 ]. A QCA consists of a lattice of cells, each holding a finite-dimensional quantum state, whose evolution is defined by repeated application of local, translation-invariant rules. They are basically the equivalent of Cellular Automatons, which are beautifully described in Wolfram MathWorld as: a collection of \"colored\" cells on a grid of specified shape that evolves through a number of discrete time steps according to a set of rules based on the states of neighboring cells. In QCAs evolution ensure that information propagates only within a bounded neighborhood per time step, enforcing causality and making QCAs suitable for modeling distributed quantum dynamics. Similarly to quantum walks, their dynamics can be reduced to two core operations: Unitary updates: local reversible transformations that map a neighborhood $A$ to output cells $B$, preserving causality and unitarity, Swap or shift layers: structural steps to rearrange or relabel cell contents for staggered updates. You can think of QCA operation evolution as a slow conquer of a substrate lattice: They can be mapped to HDHs through: import hdh from hdh.models.qca import QCA from hdh.visualize import plot_hdh # Topology of lattice over which QCA will evolve topology = { \"q0\": [\"q1\", \"q2\"], \"q1\": [\"q0\"], \"q2\": [\"q0\"] } measurements = {\"q1\", \"q2\"} qca = QCA(topology=topology, measurements=measurements, steps=3) hdh = qca.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: This is the corresponding motif to operation mapping table for the QCA model: Built in Converters The library currently has converters from Qiskit , OpenQASM , Cirq , Amazon Braket SDK , and PennyLane . These converters take in computations written in these languages/SDKs and transform them into relevant HDHs. They can be used as follows: import hdh import qiskit from qiskit import QuantumCircuit from hdh.converters import from_qiskit from hdh.visualize import plot_hdh from hdh.passes.cut import compute_cut, cost, partition_sizes, compute_parallelism_by_time # Qiskit circuit qc = QuantumCircuit(3) qc.h(0) qc.cx(0, 1) qc.ccx(1, 2, 0) qc.measure_all() hdh_graph = from_qiskit(qc) # Generate HDH fig = plot_hdh(hdh) # Visualize HDH Make your own instruction set Beyond the given models and converters, you can also make your own model class by defining the desired HDH motif construction. A good rule of thumb is to consider inputs and outputs of operations as nodes and the operations themselves as hyperedges. This is how the Circuit class looks like: from typing import List, Tuple, Optional, Set, Dict, Literal import sys import os sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) from hdh.hdh import HDH class Circuit: def __init__(self): self.instructions: List[ Tuple[str, List[int], List[int], List[bool], Literal[\"a\", \"p\"]] ] = [] # (name, qubits, bits, modifies_flags, cond_flag) def add_instruction( self, name: str, qubits: List[int], bits: Optional[List[int]] = None, modifies_flags: Optional[List[bool]] = None, cond_flag: Literal[\"a\", \"p\"] = \"a\" ): name = name.lower() if name == \"measure\": modifies_flags = [True] * len(qubits) else: bits = bits or [] modifies_flags = modifies_flags or [True] * len(qubits) self.instructions.append((name, qubits, bits, modifies_flags, cond_flag)) def build_hdh(self, hdh_cls=HDH) -> HDH: hdh = hdh_cls() qubit_time: Dict[int, int] = {} bit_time: Dict[int, int] = {} last_gate_input_time: Dict[int, int] = {} for name, qargs, cargs, modifies_flags, cond_flag in self.instructions: # --- Canonicalize inputs --- qargs = list(qargs or []) if name == \"measure\": cargs = list(cargs) if cargs is not None else qargs.copy() # 1:1 map if len(cargs) != len(qargs): raise ValueError(\"measure: len(bits) must equal len(qubits)\") modifies_flags = [True] * len(qargs) else: cargs = list(cargs or []) if modifies_flags is None: modifies_flags = [True] * len(qargs) elif len(modifies_flags) != len(qargs): raise ValueError(\"len(modifies_flags) must equal len(qubits)\") #print(f\"\\n=== Adding instruction: {name} on qubits {qargs} ===\") # for q in qargs: #print(f\" [before] qubit_time[{q}] = {qubit_time.get(q)}\") # Measurements if name == \"measure\": for i, qubit in enumerate(qargs): # Use current qubit time (default 0), do NOT advance it here t_in = qubit_time.get(qubit, 0) q_in = f\"q{qubit}_t{t_in}\" hdh.add_node(q_in, \"q\", t_in, node_real=cond_flag) bit = cargs[i] t_out = t_in + 1 # classical result at next tick c_out = f\"c{bit}_t{t_out}\" hdh.add_node(c_out, \"c\", t_out, node_real=cond_flag) hdh.add_hyperedge({q_in, c_out}, \"c\", name=\"measure\", node_real=cond_flag) # Next-free convention for this bit stream bit_time[bit] = t_out + 1 # Important: do NOT set qubit_time[qubit] = t_in + k # The quantum wire collapses; keep its last quantum tick unchanged. continue # Conditional gate handling if name != \"measure\" and cond_flag == \"p\" and cargs: # Supports 1 classical control; extend to many if you like ctrl = cargs[0] # Ensure times exist for q in qargs: if q not in qubit_time: qubit_time[q] = max(qubit_time.values(), default=0) last_gate_input_time[q] = qubit_time[q] # Classical node must already exist (e.g., produced by a prior measure) # bit_time points to \"next free\" slot; the latest existing node is at t = bit_time-1 c_latest = bit_time.get(ctrl, 1) - 1 cnode = f\"c{ctrl}_t{c_latest}\" hdh.add_node(cnode, \"c\", c_latest, node_real=cond_flag) edges = [] for tq in qargs: # gate happens at next tick after both inputs are ready t_in_q = qubit_time[tq] t_gate = max(t_in_q, c_latest) + 1 qname = f\"q{tq}\" qout = f\"{qname}_t{t_gate}\" # ensure the quantum output node exists at gate time hdh.add_node(qout, \"q\", t_gate, node_real=cond_flag) # add classical hyperedge feeding the quantum node e = hdh.add_hyperedge({cnode, qout}, \"c\", name=name, node_real=cond_flag) edges.append(e) # advance quantum time last_gate_input_time[tq] = t_in_q qubit_time[tq] = t_gate # store edge_args for reconstruction/debug q_with_time = [(q, qubit_time[q]) for q in qargs] c_with_time = [(ctrl, c_latest + 1)] # next-free convention; adjust if you track exact for e in edges: hdh.edge_args[e] = (q_with_time, c_with_time, modifies_flags or [True] * len(qargs)) continue #Actualized gate (non-conditional) for q in qargs: if q not in qubit_time: qubit_time[q] = max(qubit_time.values(), default=0) last_gate_input_time[q] = qubit_time[q] # initial input time active_times = [qubit_time[q] for q in qargs] time_step = max(active_times) + 1 if active_times else 0 in_nodes: List[str] = [] out_nodes: List[str] = [] intermediate_nodes: List[str] = [] final_nodes: List[str] = [] post_nodes: List[str] = [] #DEBUG #print(\" [after]\", {q: qubit_time[q] for q in qargs}) #print(\" [after]\", {q: qubit_time[q] for q in qargs}) multi_gate = (name != \"measure\" and len(qargs) > 1) common_start = max((qubit_time.get(q, 0) for q in qargs), default=0) if multi_gate else None for i, qubit in enumerate(qargs): t_in = qubit_time[qubit] qname = f\"q{qubit}\" in_id = f\"{qname}_t{t_in}\" hdh.add_node(in_id, \"q\", t_in, node_real=cond_flag) #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") in_nodes.append(in_id) #print(f\" [qubit {qubit}] modifies_flag = {modifies_flags[i]}\") #print(f\" [qubit {qubit}] modifies_flag = {modifies_flags[i]}\") # choose timeline if multi_gate: t1 = common_start + 1 t2 = common_start + 2 t3 = common_start + 3 else: t1 = t_in + 1 t2 = t1 + 1 t3 = t2 + 1 # create mid/final/post nodes for BOTH cases mid_id = f\"{qname}_t{t1}\" final_id = f\"{qname}_t{t2}\" post_id = f\"{qname}_t{t3}\" hdh.add_node(mid_id, \"q\", t1, node_real=cond_flag) hdh.add_node(final_id, \"q\", t2, node_real=cond_flag) hdh.add_node(post_id, \"q\", t3, node_real=cond_flag) intermediate_nodes.append(mid_id) final_nodes.append(final_id) post_nodes.append(post_id) last_gate_input_time[qubit] = t_in qubit_time[qubit] = t3 edges = [] if len(qargs) > 1: # Stage 1: input \u2192 intermediate (1:1) for in_node, mid_node in zip(in_nodes, intermediate_nodes): e = hdh.add_hyperedge({in_node, mid_node}, \"q\", name=f\"{name}_stage1\", node_real=cond_flag) #print(f\" [~] stage1 {in_node} \u2192 {mid_node}\") #print(f\" [~] stage1 {in_node} \u2192 {mid_node}\") edges.append(e) # Stage 2: full multiqubit edge from intermediate \u2192 final e2 = hdh.add_hyperedge(set(intermediate_nodes) | set(final_nodes), \"q\", name=f\"{name}_stage2\", node_real=cond_flag) #print(f\" [~] stage2 |intermediate|={len(intermediate_nodes)} \u2192 |final|={len(final_nodes)}\") #print(f\" [~] stage2 |intermediate|={len(intermediate_nodes)} \u2192 |final|={len(final_nodes)}\") edges.append(e2) # Stage 3: final \u2192 post (1:1) for f_node, p_node in zip(final_nodes, post_nodes): e = hdh.add_hyperedge({f_node, p_node}, \"q\", name=f\"{name}_stage3\", node_real=cond_flag) #print(f\" [~] stage3 {f_node} \u2192 {p_node}\") #print(f\" [~] stage3 {f_node} \u2192 {p_node}\") edges.append(e) if name == \"measure\": for i, qubit in enumerate(qargs): t_in = qubit_time.get(qubit, 0) q_in = f\"q{qubit}_t{t_in}\" hdh.add_node(q_in, \"q\", t_in, node_real=cond_flag) bit = cargs[i] t_out = t_in + 1 c_out = f\"c{bit}_t{t_out}\" hdh.add_node(c_out, \"c\", t_out, node_real=cond_flag) hdh.add_hyperedge({q_in, c_out}, \"c\", name=\"measure\", node_real=cond_flag) bit_time[bit] = t_out + 1 continue if name != \"measure\": for bit in cargs: t = bit_time.get(bit, 0) cname = f\"c{bit}\" out_id = f\"{cname}_t{t + 1}\" hdh.add_node(out_id, \"c\", t + 1, node_real=cond_flag) out_nodes.append(out_id) bit_time[bit] = t + 1 all_nodes = set(in_nodes) | set(out_nodes) if all(n.startswith(\"c\") for n in all_nodes): edge_type = \"c\" elif any(n.startswith(\"c\") for n in all_nodes): edge_type = \"c\" else: edge_type = \"q\" edges = [] if len(qargs) > 1: # Multi-qubit gate # Stage 1: input \u2192 intermediate (1:1) for in_node, mid_node in zip(in_nodes, intermediate_nodes): edge = hdh.add_hyperedge({in_node, mid_node}, \"q\", name=f\"{name}_stage1\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") edges.append(edge) # Stage 2: full multiqubit edge from intermediate \u2192 final edge2 = hdh.add_hyperedge(set(intermediate_nodes) | set(final_nodes), \"q\", name=f\"{name}_stage2\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage2\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage2\") edges.append(edge2) # Stage 3: final \u2192 post (1:1 again) for final_node, post_node in zip(final_nodes, post_nodes): edge = hdh.add_hyperedge({final_node, post_node}, \"q\", name=f\"{name}_stage3\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") edges.append(edge) else: # Single-qubit gate for i, qubit in enumerate(qargs): if modifies_flags[i] and name != \"measure\": t_in = last_gate_input_time[qubit] t_out = t_in + 1 qname = f\"q{qubit}\" in_id = f\"{qname}_t{t_in}\" out_id = f\"{qname}_t{t_out}\" # DEBUG #print(f\"[{name}] Q{qubit} t_in = {t_in}, expected from qubit_time = {qubit_time[qubit]}\") #print(f\"[{name}] Q{qubit} t_in = {t_in}, expected from qubit_time = {qubit_time[qubit]}\") hdh.add_node(out_id, \"q\", t_out, node_real=cond_flag) # DEBUG #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") edge = hdh.add_hyperedge({in_id, out_id}, \"q\", name=name, node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_id} \u2192 {out_id}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_id} \u2192 {out_id}, label: {name}_stage1\") edges.append(edge) # Update time qubit_time[qubit] = t_out last_gate_input_time[qubit] = t_in q_with_time = [(q, qubit_time[q]) for q in qargs] c_with_time = [(c, bit_time.get(c, 0)) for c in cargs] for edge in edges: hdh.edge_args[edge] = (q_with_time, c_with_time, modifies_flags) return hdh","title":"Quantum Computational Model mappings to HDHs"},{"location":"models/#computational-models","text":"Quantum computation can be performed with various computational models that have different instruction sets, such as quantum circuits (which perform computation through gates) or measurement based patterns (which perform computation through corrections). The diversity between these models can be attributed to hardware constraints as well as to the age of the field. Although they are all equivalent and computations can theoretically be translated accross them, this process is inneficient and hard to due to a lack of clear set of cross-model translators. HDHs were designed to abstract all the models into a unified framework. As such, they are model agnostic and can be constructed from any set of instructions. Specific model classes can be found under the hdh/models folder. To facilitate the usage of HDHs, the library has a set of embedded model mappings which translate instruction sets from popular quantum computational models into reusable HDH motifs. You can find details and examples of how to use these model classes and SDK converters bellow.","title":"Computational models"},{"location":"models/#circuits","text":"The circuit model is among the most widely adopted paradigms of quantum computation, particularly in implementations on industrial quantum hardware (with the notable exception of photonic qubits). Quantum circuits are a universal model of computation. They form the foundation of many leading quantum software packages, including Qiskit , OpenQASM , Cirq , Amazon Braket SDK , and PennyLane ; which you can directly map to the librarys' Circuit class and then to HDHs (see examples of how to use these converters bellow). A quantum circuit is composed of a sequence of quantum gates applied to a set of qubits (commonly represented as horizontal wires). Gates, visualized as boxes placed on these wires, may act on one or multiple qubits. Single-qubit gates correspond to rotations of the qubit\u2019s state vector on the Bloch sphere. For example, a Z-rotation by angle \u03c0 rotates the state vector by \u03c0 radians about the z-axis. Multi-qubit gates, such as controlled-X (CX), act conditionally on one qubit\u2019s state and thereby create dependencies among qubits. For instance, a CX gate applies an X gate to the target qubit only if the control qubit is in the \u22231\u27e9 state. Such gates generate entanglement, as discussed in the introduction to DQC . Beyond static gates, circuits also support classically conditioned operations. For example, an IfElse construct applies one subcircuit if a specified classical register holds a given value and another subcircuit otherwise. This enables hybrid quantum\u2013classical flow control within circuits. Finally, measurement operations project qubits into classical bits, irreversibly collapsing their quantum state. The goal of HDHs is to make explicit the transformations induced by all gates and measurements, enabling large circuits to be partitioned into smaller, distributable subcircuits. Mapping a quantum circuit into an HDH involves applying the correspondences summarized in the table below: Bellow is an example of how to build a circuit using the library\u2019s Circuit class and map it to an HDH: import hdh from hdh.models.circuit import Circuit from hdh.visualize import plot_hdh circuit = Circuit() # Set of instructions circuit.add_instruction(\"ccx\", [0, 1, 2]) circuit.add_instruction(\"h\", [3]) circuit.add_instruction(\"h\", [5]) circuit.add_instruction(\"cx\", [3, 4]) circuit.add_instruction(\"cx\", [2, 1]) # NOTE: The example with the line bellow uncommented will be added soon # circuit.add_conditional_gate(5, 4, \"z\") circuit.add_instruction(\"cx\", [0, 3]) circuit.add_instruction(\"measure\", [2]) circuit.add_instruction(\"measure\", [4]) hdh = circuit.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code is equivalent to the following circuit: Which is mapped to HDH: The HDH is composed of the motifs shown in the mapping table, appearing in the temporal order of computation and indexed by the qubits they abstract. Note that a qubit is not initialized until the timestep immediately preceding its first operation.","title":"Circuits"},{"location":"models/#mbqc-patterns","text":"Measurement based quantum computing is one of the alternative universal models to quantum circuits [ 3 ]. It can be implemented on photonic quantum computers, as is often paired alongside fusion gates [ 4 ]. MBQC patterns consist of 4 types of operations [ 5 ]: N: Auxiliary state preparations E: Entaglement operations M: Measurements C: Corrections Intuitively, MBQC patterns can be thought of as large cluster states built from entangled nodes. The computation proceeds by measuring these nodes in sequence, where later measurement bases are adapted according to the outcomes of earlier ones. Measurement based patterns may look like this (taken from 6 ): . Here the N operations form the nodes, and E operations make the Edges. Time flows from left to right; and the angles (0, \u03c0/8) correspond to correction angles. Equivalences between circuit gates and MBQC patterns can be drawn (in this case squares = output qubits) [ 6 ]: But they are not necessarily the most efficient use of the model. Many MBQC native algorithms have been proposed [ 7 , 8 ], and the model is very compatible with various error correction techniques. If you'd like a more in depth tutorial on the model we recommend this pennylane tutorial on MBQC . Distribution of MBQC patterns can be confused with the partitioning of the substrate cluster state over which they are computed (the network you see). This is a valid method for partitioning the computation, but it is not the one that HDHs offer. As in the circuit model, HDHs abstract the operations performed during the computation (atop the cluster or during cluster generation) in a way that reflects not only their entanglement dependencies but also their temporal dependencies (aka the order in which they are performed). Mapping MBQC patterns to HDHs is relatively simple: import hdh from hdh.models.mbqc import MBQC from hdh.visualize import plot_hdh mbqc = MBQC() # Set of instructions mbqc.add_operation(\"N\", [], \"q0\") mbqc.add_operation(\"N\", [], \"q1\") mbqc.add_operation(\"E\", [\"q0\", \"q1\"], \"q1\") mbqc.add_operation(\"M\", [\"q0\"], \"c0\") mbqc.add_operation(\"C\", [\"c0\"], \"q2\") hdh = mbqc.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: Unlike in the circuit model, MBQC pattern operations are not \"automatically\" assigned to the q_ and c_ naming conventions. This is because a node in an MBQC pattern doesn't necessarily directly correspond to a qubit. For simplicity we have made it so in the example above, but feel free to name them something else. Note that if you do the visualize function may play some tricks on you depending on the version of the library you are working with. This is the corresponding motif to operation mapping table for the MBQC model:","title":"MBQC patterns"},{"location":"models/#quantum-walks","text":"Quantum walks are another universal model of quantum computation [ 9 ]. Like quantum circuits, quantum walks can be expressed using different sets of unitary operations and are universal for quantum computation. However, unlike circuits, quantum walks are not inherently defined in terms of gate sequences, they are abstract evolution models that can be implemented via gates or analog dynamics depending on the platform. They come in various forms, typically categorized as discrete-time or continuous-time variants [ 10 ]. In discrete-time walks (DTQW), evolution proceeds in steps using a coin operator and a shift operator; while continuous-time walks (CTQW) evolve directly under a Hamiltonian. In both cases, the key idea is that the walker\u2019s amplitude spreads across positions in superposition, creating interference patterns that can be harnessed for computation. This interference, guided by the chosen coin or Hamiltonian, allows quantum walks to implement algorithms and decision processes that outperform their classical counterparts. Unlike classical random walks, where probabilities govern independent step outcomes, quantum walks evolve coherently under unitary dynamics, so amplitudes rather than probabilities interfere. Perhaps a useful visualisation of this is to view quantum walks as waves spreading across all paths simultaneously, as per the image bellow (taken from [ 11 ]), where the two peaks of the amplitude distribution at the final row can be seen at the edges, in contrast to the central Gaussian-like spread (red) of the classical walk: The reason why the distributions are different is that in a classical walk, each step is an independent random choice. Adding them up gives a binomial distribution, which converges to a Gaussian around the center. In a quantum walk, the walker is in a superposition of paths. At each step, amplitudes for moving left or right interfere. Constructive interference pushes weight toward the outer edges, while destructive interference cancels amplitudes near the center. As a result, the probability distribution spreads ballistically (linearly with the number of steps) rather than diffusively (square root of steps), and peaks form at the farthest positions the walker can reach. You can map QW to HDHs as per: import hdh from hdh.models.qw import QW from hdh.visualize import plot_hdh qw = QW(type=discrete) # Set of instructions q0 = \"q0\" q1 = qw.add_coin(q0) q2 = qw.add_shift(q1) qw.add_measurement(q2, \"c0\") hdh = qw.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: This is the corresponding motif to operation mapping table for the QW model: Bellow you can find a short explanation explaining the differences between DTQW and CTQW implementations. If you're interested in QW, we recommend this book .","title":"Quantum walks"},{"location":"models/#discrete-time-quantum-walks","text":"A DTQW is made up of a set of timed operations imposed by its coin and walker. If we where to equate this to the NEMC format for MBQC, DTQW operations would be of two types: Coin: local unitaries acting on internal degrees of freedom at each position, e.g., internal \"spin\" or coin states, Shift: conditional displacements of walker states in position space based on the coin state. The outputs of each coin toss serve as inputs to the subsequent shift. A DTQW is \"valid\" if all operations can be sequentially ordered. Their mapping to HDHs is straightforward: inputs and outputs align naturally with state nodes, while coin and shift operations correspond to channel hyperedges. In practice, each coin operation introduces a local unitary hyperedge attached to the state node representing the walker\u2019s internal degree of freedom at a given time. Each shift operation then acts as a conditional hyperedge spanning the relevant position nodes, effectively redirecting walker states according to the coin outcome. Because HDHs are time-respecting, the sequential interplay of coin and shift steps is preserved explicitly, making the walk\u2019s evolution appear as an alternating pattern of local and conditional hyperedges across timesteps.","title":"Discrete Time Quantum Walks"},{"location":"models/#continuous-time-quantum-walks","text":"In contrast, CTQWs describe physical evolution over time under a Hamiltonian and do not, by themselves, constitute a universal computational model. They lack a well-defined, manipulable set of time-indexed operations. Nonetheless, CTQWs can still be mapped to HDH constructions by interpreting their continuous evolution as a resource-driven process. HDHs accommodate this by using dedicated predictive constructs to represent these operations. In other words they discretize the CTQW, and map it using the DTQW mapping, whilst setting each operation to the predicted type. This logic can be extended to other prominent quantum frameworks, such as adiabatic quantum computing, which likewise lack native representations of sequential logical operations but can still be encoded into HDHs by discretizing their dynamics and treating them as structured evolution patterns.","title":"Continuous Time Quantum Walks"},{"location":"models/#quantum-cellular-automata","text":"Finally, the last model currently compatible with the HDH library is QCA (Quantum cellular automaton). QCAs originally arose as an alternative paradigm for quantum computation, though more recently they have found application in understanding topological phases of matter and have been proposed as models of periodically driven (Floquet) quantum systems [ 12 ]. A QCA consists of a lattice of cells, each holding a finite-dimensional quantum state, whose evolution is defined by repeated application of local, translation-invariant rules. They are basically the equivalent of Cellular Automatons, which are beautifully described in Wolfram MathWorld as: a collection of \"colored\" cells on a grid of specified shape that evolves through a number of discrete time steps according to a set of rules based on the states of neighboring cells. In QCAs evolution ensure that information propagates only within a bounded neighborhood per time step, enforcing causality and making QCAs suitable for modeling distributed quantum dynamics. Similarly to quantum walks, their dynamics can be reduced to two core operations: Unitary updates: local reversible transformations that map a neighborhood $A$ to output cells $B$, preserving causality and unitarity, Swap or shift layers: structural steps to rearrange or relabel cell contents for staggered updates. You can think of QCA operation evolution as a slow conquer of a substrate lattice: They can be mapped to HDHs through: import hdh from hdh.models.qca import QCA from hdh.visualize import plot_hdh # Topology of lattice over which QCA will evolve topology = { \"q0\": [\"q1\", \"q2\"], \"q1\": [\"q0\"], \"q2\": [\"q0\"] } measurements = {\"q1\", \"q2\"} qca = QCA(topology=topology, measurements=measurements, steps=3) hdh = qca.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH This code generates HDH: This is the corresponding motif to operation mapping table for the QCA model:","title":"Quantum cellular automata"},{"location":"models/#built-in-converters","text":"The library currently has converters from Qiskit , OpenQASM , Cirq , Amazon Braket SDK , and PennyLane . These converters take in computations written in these languages/SDKs and transform them into relevant HDHs. They can be used as follows: import hdh import qiskit from qiskit import QuantumCircuit from hdh.converters import from_qiskit from hdh.visualize import plot_hdh from hdh.passes.cut import compute_cut, cost, partition_sizes, compute_parallelism_by_time # Qiskit circuit qc = QuantumCircuit(3) qc.h(0) qc.cx(0, 1) qc.ccx(1, 2, 0) qc.measure_all() hdh_graph = from_qiskit(qc) # Generate HDH fig = plot_hdh(hdh) # Visualize HDH","title":"Built in Converters"},{"location":"models/#make-your-own-instruction-set","text":"Beyond the given models and converters, you can also make your own model class by defining the desired HDH motif construction. A good rule of thumb is to consider inputs and outputs of operations as nodes and the operations themselves as hyperedges. This is how the Circuit class looks like: from typing import List, Tuple, Optional, Set, Dict, Literal import sys import os sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) from hdh.hdh import HDH class Circuit: def __init__(self): self.instructions: List[ Tuple[str, List[int], List[int], List[bool], Literal[\"a\", \"p\"]] ] = [] # (name, qubits, bits, modifies_flags, cond_flag) def add_instruction( self, name: str, qubits: List[int], bits: Optional[List[int]] = None, modifies_flags: Optional[List[bool]] = None, cond_flag: Literal[\"a\", \"p\"] = \"a\" ): name = name.lower() if name == \"measure\": modifies_flags = [True] * len(qubits) else: bits = bits or [] modifies_flags = modifies_flags or [True] * len(qubits) self.instructions.append((name, qubits, bits, modifies_flags, cond_flag)) def build_hdh(self, hdh_cls=HDH) -> HDH: hdh = hdh_cls() qubit_time: Dict[int, int] = {} bit_time: Dict[int, int] = {} last_gate_input_time: Dict[int, int] = {} for name, qargs, cargs, modifies_flags, cond_flag in self.instructions: # --- Canonicalize inputs --- qargs = list(qargs or []) if name == \"measure\": cargs = list(cargs) if cargs is not None else qargs.copy() # 1:1 map if len(cargs) != len(qargs): raise ValueError(\"measure: len(bits) must equal len(qubits)\") modifies_flags = [True] * len(qargs) else: cargs = list(cargs or []) if modifies_flags is None: modifies_flags = [True] * len(qargs) elif len(modifies_flags) != len(qargs): raise ValueError(\"len(modifies_flags) must equal len(qubits)\") #print(f\"\\n=== Adding instruction: {name} on qubits {qargs} ===\") # for q in qargs: #print(f\" [before] qubit_time[{q}] = {qubit_time.get(q)}\") # Measurements if name == \"measure\": for i, qubit in enumerate(qargs): # Use current qubit time (default 0), do NOT advance it here t_in = qubit_time.get(qubit, 0) q_in = f\"q{qubit}_t{t_in}\" hdh.add_node(q_in, \"q\", t_in, node_real=cond_flag) bit = cargs[i] t_out = t_in + 1 # classical result at next tick c_out = f\"c{bit}_t{t_out}\" hdh.add_node(c_out, \"c\", t_out, node_real=cond_flag) hdh.add_hyperedge({q_in, c_out}, \"c\", name=\"measure\", node_real=cond_flag) # Next-free convention for this bit stream bit_time[bit] = t_out + 1 # Important: do NOT set qubit_time[qubit] = t_in + k # The quantum wire collapses; keep its last quantum tick unchanged. continue # Conditional gate handling if name != \"measure\" and cond_flag == \"p\" and cargs: # Supports 1 classical control; extend to many if you like ctrl = cargs[0] # Ensure times exist for q in qargs: if q not in qubit_time: qubit_time[q] = max(qubit_time.values(), default=0) last_gate_input_time[q] = qubit_time[q] # Classical node must already exist (e.g., produced by a prior measure) # bit_time points to \"next free\" slot; the latest existing node is at t = bit_time-1 c_latest = bit_time.get(ctrl, 1) - 1 cnode = f\"c{ctrl}_t{c_latest}\" hdh.add_node(cnode, \"c\", c_latest, node_real=cond_flag) edges = [] for tq in qargs: # gate happens at next tick after both inputs are ready t_in_q = qubit_time[tq] t_gate = max(t_in_q, c_latest) + 1 qname = f\"q{tq}\" qout = f\"{qname}_t{t_gate}\" # ensure the quantum output node exists at gate time hdh.add_node(qout, \"q\", t_gate, node_real=cond_flag) # add classical hyperedge feeding the quantum node e = hdh.add_hyperedge({cnode, qout}, \"c\", name=name, node_real=cond_flag) edges.append(e) # advance quantum time last_gate_input_time[tq] = t_in_q qubit_time[tq] = t_gate # store edge_args for reconstruction/debug q_with_time = [(q, qubit_time[q]) for q in qargs] c_with_time = [(ctrl, c_latest + 1)] # next-free convention; adjust if you track exact for e in edges: hdh.edge_args[e] = (q_with_time, c_with_time, modifies_flags or [True] * len(qargs)) continue #Actualized gate (non-conditional) for q in qargs: if q not in qubit_time: qubit_time[q] = max(qubit_time.values(), default=0) last_gate_input_time[q] = qubit_time[q] # initial input time active_times = [qubit_time[q] for q in qargs] time_step = max(active_times) + 1 if active_times else 0 in_nodes: List[str] = [] out_nodes: List[str] = [] intermediate_nodes: List[str] = [] final_nodes: List[str] = [] post_nodes: List[str] = [] #DEBUG #print(\" [after]\", {q: qubit_time[q] for q in qargs}) #print(\" [after]\", {q: qubit_time[q] for q in qargs}) multi_gate = (name != \"measure\" and len(qargs) > 1) common_start = max((qubit_time.get(q, 0) for q in qargs), default=0) if multi_gate else None for i, qubit in enumerate(qargs): t_in = qubit_time[qubit] qname = f\"q{qubit}\" in_id = f\"{qname}_t{t_in}\" hdh.add_node(in_id, \"q\", t_in, node_real=cond_flag) #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") in_nodes.append(in_id) #print(f\" [qubit {qubit}] modifies_flag = {modifies_flags[i]}\") #print(f\" [qubit {qubit}] modifies_flag = {modifies_flags[i]}\") # choose timeline if multi_gate: t1 = common_start + 1 t2 = common_start + 2 t3 = common_start + 3 else: t1 = t_in + 1 t2 = t1 + 1 t3 = t2 + 1 # create mid/final/post nodes for BOTH cases mid_id = f\"{qname}_t{t1}\" final_id = f\"{qname}_t{t2}\" post_id = f\"{qname}_t{t3}\" hdh.add_node(mid_id, \"q\", t1, node_real=cond_flag) hdh.add_node(final_id, \"q\", t2, node_real=cond_flag) hdh.add_node(post_id, \"q\", t3, node_real=cond_flag) intermediate_nodes.append(mid_id) final_nodes.append(final_id) post_nodes.append(post_id) last_gate_input_time[qubit] = t_in qubit_time[qubit] = t3 edges = [] if len(qargs) > 1: # Stage 1: input \u2192 intermediate (1:1) for in_node, mid_node in zip(in_nodes, intermediate_nodes): e = hdh.add_hyperedge({in_node, mid_node}, \"q\", name=f\"{name}_stage1\", node_real=cond_flag) #print(f\" [~] stage1 {in_node} \u2192 {mid_node}\") #print(f\" [~] stage1 {in_node} \u2192 {mid_node}\") edges.append(e) # Stage 2: full multiqubit edge from intermediate \u2192 final e2 = hdh.add_hyperedge(set(intermediate_nodes) | set(final_nodes), \"q\", name=f\"{name}_stage2\", node_real=cond_flag) #print(f\" [~] stage2 |intermediate|={len(intermediate_nodes)} \u2192 |final|={len(final_nodes)}\") #print(f\" [~] stage2 |intermediate|={len(intermediate_nodes)} \u2192 |final|={len(final_nodes)}\") edges.append(e2) # Stage 3: final \u2192 post (1:1) for f_node, p_node in zip(final_nodes, post_nodes): e = hdh.add_hyperedge({f_node, p_node}, \"q\", name=f\"{name}_stage3\", node_real=cond_flag) #print(f\" [~] stage3 {f_node} \u2192 {p_node}\") #print(f\" [~] stage3 {f_node} \u2192 {p_node}\") edges.append(e) if name == \"measure\": for i, qubit in enumerate(qargs): t_in = qubit_time.get(qubit, 0) q_in = f\"q{qubit}_t{t_in}\" hdh.add_node(q_in, \"q\", t_in, node_real=cond_flag) bit = cargs[i] t_out = t_in + 1 c_out = f\"c{bit}_t{t_out}\" hdh.add_node(c_out, \"c\", t_out, node_real=cond_flag) hdh.add_hyperedge({q_in, c_out}, \"c\", name=\"measure\", node_real=cond_flag) bit_time[bit] = t_out + 1 continue if name != \"measure\": for bit in cargs: t = bit_time.get(bit, 0) cname = f\"c{bit}\" out_id = f\"{cname}_t{t + 1}\" hdh.add_node(out_id, \"c\", t + 1, node_real=cond_flag) out_nodes.append(out_id) bit_time[bit] = t + 1 all_nodes = set(in_nodes) | set(out_nodes) if all(n.startswith(\"c\") for n in all_nodes): edge_type = \"c\" elif any(n.startswith(\"c\") for n in all_nodes): edge_type = \"c\" else: edge_type = \"q\" edges = [] if len(qargs) > 1: # Multi-qubit gate # Stage 1: input \u2192 intermediate (1:1) for in_node, mid_node in zip(in_nodes, intermediate_nodes): edge = hdh.add_hyperedge({in_node, mid_node}, \"q\", name=f\"{name}_stage1\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") edges.append(edge) # Stage 2: full multiqubit edge from intermediate \u2192 final edge2 = hdh.add_hyperedge(set(intermediate_nodes) | set(final_nodes), \"q\", name=f\"{name}_stage2\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage2\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage2\") edges.append(edge2) # Stage 3: final \u2192 post (1:1 again) for final_node, post_node in zip(final_nodes, post_nodes): edge = hdh.add_hyperedge({final_node, post_node}, \"q\", name=f\"{name}_stage3\", node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_node} \u2192 {mid_node}, label: {name}_stage1\") edges.append(edge) else: # Single-qubit gate for i, qubit in enumerate(qargs): if modifies_flags[i] and name != \"measure\": t_in = last_gate_input_time[qubit] t_out = t_in + 1 qname = f\"q{qubit}\" in_id = f\"{qname}_t{t_in}\" out_id = f\"{qname}_t{t_out}\" # DEBUG #print(f\"[{name}] Q{qubit} t_in = {t_in}, expected from qubit_time = {qubit_time[qubit]}\") #print(f\"[{name}] Q{qubit} t_in = {t_in}, expected from qubit_time = {qubit_time[qubit]}\") hdh.add_node(out_id, \"q\", t_out, node_real=cond_flag) # DEBUG #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") #print(f\" [+] Node added: {in_id} (type q, time {t_in})\") edge = hdh.add_hyperedge({in_id, out_id}, \"q\", name=name, node_real=cond_flag) # DEBUG #print(f\" [~] Hyperedge added over: {in_id} \u2192 {out_id}, label: {name}_stage1\") #print(f\" [~] Hyperedge added over: {in_id} \u2192 {out_id}, label: {name}_stage1\") edges.append(edge) # Update time qubit_time[qubit] = t_out last_gate_input_time[qubit] = t_in q_with_time = [(q, qubit_time[q]) for q in qargs] c_with_time = [(c, bit_time.get(c, 0)) for c in cargs] for edge in edges: hdh.edge_args[edge] = (q_with_time, c_with_time, modifies_flags) return hdh","title":"Make your own instruction set"},{"location":"passes/","text":"HDH Partitioning Utilities Here is an overview of the partitioning utilities available in the HDH library, designed to distribute quantum computations across multiple devices. Partitioning HDHs for Distribution The hdh/passes directory contains scripts for partitioning and manipulating HDH graphs. The primary file for partitioning is cut.py , which offers two main approaches: a greedy, HDH-aware method and a METIS-based method operating on a qubit graph representation (telegate). Greedy HDH Partitioner The main partitioning function is compute_cut , which implements a greedy, bin-filling algorithm with hypergraph awareness. Here's how it works: Core Mechanics Node-level assignment: The partitioner assigns individual nodes of the HDH graph to bins. Qubit-based capacity: While the assignment is at the node level, the capacity of each bin is determined by the number of unique qubits it contains. Automatic sibling placement: Once a node corresponding to a particular qubit is placed in a bin, all other nodes associated with that same qubit are automatically assigned to the same bin. This ensures that all temporal instances of a qubit remain co-located. Algorithm Details The algorithm operates in two main phases: a beam-search-based bin-filling phase, followed by a round-robin mop-up phase. Phase 1: Main Bin-Filling (Beam Search) Step 1 - Ordering and Representative Selection: Each qubit in the quantum circuit may appear at multiple time steps (e.g., qubit 0 at time 1, time 5, time 12). The algorithm: 1. Selects ONE representative node for each qubit - specifically, the node with the highest weighted degree (most connections to other operations) 2. Sorts these representatives in descending order of their weighted degrees Why? Placing highly connected qubits first gives the algorithm more context to make informed placement decisions. It's like seating the most social people at a party first - they help determine where their friends should sit. Step 2 - Beam Search for Candidate Selection: For each bin being filled, instead of greedily picking just the single best node (which might not fit due to capacity), the algorithm uses beam search to keep the top beam_k candidates. What is Beam Search? Beam search is a heuristic that balances between: - Greedy search (k=1): Only considers the single best option - fast but inflexible - Exhaustive search (k=\u221e): Considers all options - thorough but slow - Beam search (k=3 default): Keeps the top k candidates - good balance Example with 50 unassigned qubits and beam_k=3: 1. Evaluate all 50 qubits based on: - Delta cost: How much would placing this node increase cut cost? - Frontier score: How well connected is this node to nodes already in the bin? 2. Keep top 3 candidates: - Qubit 42: delta_cost=-5, frontier_score=100 (BEST) - Qubit 17: delta_cost=-4, frontier_score=95 (2nd best) - Qubit 23: delta_cost=-3, frontier_score=90 (3rd best) 3. Check capacity constraints for each in order: - Qubit 42: Would make bin have 26/25 qubits \u274c - Qubit 17: Would make bin have 25/25 qubits \u2713 - Place qubit 17! Effect of changing beam_k: - beam_k=1 : Fastest, but may miss good alternatives if the best choice violates capacity - beam_k=3 (default): Good balance - considers alternatives without much overhead - beam_k=10 : More thorough exploration, slower, potentially better quality for complex constraints Phase 1 Capacity Management: The \"Shadow Capacity\" System The algorithm uses a dynamic capacity model to encourage better load balancing across bins. How it works: With cap=25 qubits per bin and reserve_frac=0.08 : - Shadow capacity = 25 \u00d7 (1.0 - 0.08) = 23 qubits - Hard capacity = 25 qubits - 80% threshold = 25 \u00d7 0.8 = 20 qubits Qubits Currently in Bin Effective Capacity Limit Reasoning 0-19 qubits 23 (shadow limit) \"Save some room for later bins\" 20-25 qubits 25 (hard limit) \"Now you can fill to the top\" Why this helps: Without shadow capacity, early bins might greedily fill to 100%, leaving later bins with insufficient room for well-connected qubits. The shadow capacity ensures more even distribution. Example scenario with 4 bins and 100 qubits: - Without shadow capacity: Bins might fill as [25, 25, 25, 25] perfectly, but if you have 102 qubits, 2 are stranded - With shadow capacity: Bins fill as [23, 23, 23, 23] initially, then even out to [26, 25, 26, 25], accommodating all qubits better Fallback Seeding When: If all candidates in the beam violate capacity constraints, or if no good candidates exist. What happens: The algorithm falls back to placing the first unassigned qubit representative that fits capacity, even if it's not optimal by the scoring criteria. Why necessary: Prevents the algorithm from getting stuck when beam search finds no viable candidates. Ensures bins get initialized even in difficult cases. Phase 2: Mop-up (Round-Robin Distribution) After the main bin-filling completes, some qubits might remain unassigned. These are distributed round-robin: For each remaining unassigned qubit: Try bins in order: 0, 1, 2, 3, 0, 1, 2, 3, ... Place in first bin with available capacity If no bins have space \u2192 qubit is not placed Example: 5 qubits left: Q1, Q2, Q3, Q4, Q5 4 bins with capacity 25: Bin 0: 24/25 qubits Bin 1: 25/25 qubits (FULL) Bin 2: 23/25 qubits Bin 3: 24/25 qubits \u2192 Q1 placed in Bin 0 (now 25/25) \u2192 Q2 skips Bin 1 (full), placed in Bin 2 (now 24/25) \u2192 Q3 placed in Bin 3 (now 25/25) \u2192 Q4 placed in Bin 2 (now 25/25) \u2192 Q5 cannot be placed - all bins full Important: The round-robin phase respects the hard capacity limit . It will NOT overfill bins. If all bins are at 100% capacity and qubits remain, those qubits are skipped (not placed). To avoid unplaced qubits: Ensure k \u00d7 cap \u2265 total_number_of_qubits when calling the partitioner. Function Signature def compute_cut(hdh_graph, k: int, cap: int, *, beam_k: int = 3, backtrack_window: int = 0, polish_1swap_budget: int = 0, # disabled for HDH restarts: int = 1, reserve_frac: float = 0.08, predictive_reject: bool = True, seed: int = 0) -> Tuple[List[Set[str]], int] Parameters: * hdh_graph : The HDH graph to partition * k : Number of partitions (bins) * cap : Capacity per bin (in unique qubits) * beam_k : Beam width for candidate selection (default: 3) * backtrack_window : Currently unused (reserved for future enhancements) * polish_1swap_budget : Currently disabled for HDH partitioning * restarts : Number of random restarts to try (default: 1) * reserve_frac : Fraction of capacity to reserve until 80% full (default: 0.08) * predictive_reject : Currently unused (reserved for future enhancements) * seed : Random seed for reproducibility Returns: * A tuple of (bins_nodes, cost) where: * bins_nodes is a list of sets, each containing node IDs assigned to that bin * cost is the total cut cost (number of hyperedges spanning multiple bins) METIS Telegate Partitioner For an alternative approach to partitioning, the library provides the metis_telegate function, which leverages the METIS algorithm (with a fallback to the Kernighan-Lin algorithm if METIS is not available). Telegate Graph Construction Graph transformation: This method first converts the HDH into a \"telegate\" graph using the telegate_hdh function. In this representation: Nodes are the qubits of the quantum circuit (labeled as q{idx} ). Edges represent quantum operations between qubits (i.e., their co-appearance in a quantum hyperedge). Edge weights correspond to the multiplicity of interactions between two qubits. Quantum operation filtering: Only hyperedges marked as quantum operations (with tau attribute = \"q\") are considered when building the telegate graph. Partitioning Process METIS partitioning: The telegate graph is partitioned using the nxmetis library, which provides Python bindings to the highly efficient METIS graph partitioning tool. If METIS is unavailable, the algorithm automatically falls back to the Kernighan-Lin bisection algorithm from NetworkX. METIS attempts to respect capacity constraints through the tpwgts (target partition weights) and ubvec (unbalance vector) parameters. Overflow repair: Since METIS does not guarantee perfectly balanced partitions, a greedy rebalancing algorithm ( _repair_overflow ) is used to adjust the partitions and ensure that no bin exceeds its qubit capacity. The repair algorithm uses a heuristic gain function ( _best_move_for_node ) to choose which qubits to move between bins. It prioritizes moving qubits that minimize the increase in cut edges. Function Signature def metis_telegate(hdh: \"HDH\", partitions: int, capacities: int) -> Tuple[List[Set[str]], int, bool, str] Parameters: * hdh : The HDH graph to partition * partitions : Number of partitions (k) * capacities : Capacity per partition (in qubits) Returns: * A tuple of (bins_qubits, cut_cost, respects_capacity, method) where: * bins_qubits is a list of sets, each containing qubit IDs (as strings like \"q0\" , \"q1\" ) in that partition * cut_cost is the number of edges crossing between partitions (unweighted) * respects_capacity is a boolean indicating whether all bins satisfy the capacity constraint * method is either \"metis\" or \"kl\" indicating which algorithm was used Cut Cost Evaluation The quality of a partition is determined by the number of \"cuts\"\u2014that is, the number of hyperedges that span across multiple bins. The library provides two functions for this purpose: _total_cost_hdh Calculates the total cost of a partition on an HDH graph. This function: * Iterates through all hyperedges in the HDH * Counts a hyperedge as \"cut\" if its pins (nodes) are distributed across 2 or more bins * Returns the sum of weights of all cut hyperedges * Respects edge weights if defined in the HDH graph (defaults to 1 if not specified) Algorithm: For each hyperedge, count the number of distinct bins containing at least one pin. If this count is \u2265 2, add the edge's weight to the total cost. _cut_edges_unweighted Counts the number of edges that cross between different bins in a standard graph (used for evaluating telegate graph partitions). This function: * Takes a NetworkX graph and a partition assignment * Counts edges where the two endpoints are in different bins * Returns an unweighted count (each cut edge counts as 1) Use case: This is specifically used by metis_telegate to evaluate the quality of qubit-graph partitions. Helper Functions and Internal Components The cut.py file contains several internal helper functions that support the main partitioning algorithms: Hypergraph Incidence Structure _build_hdh_incidence : Builds the incidence structure for efficient hypergraph queries _group_qnodes : Groups nodes by their associated qubit for whole-qubit placement State Management _HDHState : A class that tracks the current partition assignment, bin loads, qubit anchoring, and pin distributions during the greedy algorithm Cost Calculation _delta_cost_hdh : Computes the incremental change in cut cost when placing a node in a bin _qubit_of : Extracts the qubit index from a node ID using regex matching Candidate Selection _best_candidates_for_bin : Selects the top-k candidate nodes for placement using beam search _first_unassigned_rep_that_fits : Fallback function to seed bins when no good candidates are found Graph Repair _repair_overflow : Greedy rebalancer to enforce bin capacity after METIS partitioning _best_move_for_node : Heuristic to compute the gain of moving a node between bins _over_under : Identifies which bins are over or under capacity Partitioning Utilities _kl_fallback_partition : Implements recursive Kernighan-Lin bisection as a fallback when METIS is unavailable The Partitioner Leaderboard For a detailed comparison of the performance of different partitioning strategies on various quantum circuits, please refer to the partitioner leaderboard in the repository's database . This can provide valuable insights into which partitioning method is best suited for your specific needs. See the database file in the documentation for more details. Notes on Evaluating Partitioners on Random Circuits We would like to warn users and partitioning strategy developers that we have found partitioners to behave differently on real quantum workloads when compared to randomly generated ones. As such, we recommend not testing partitioners on randomly generated workloads unless that is specifically your goal. Key considerations: * Circuit structure matters: Real quantum algorithms often have characteristic patterns (e.g., layered structures, specific qubit interaction patterns) that random circuits lack. * Connectivity patterns: Random circuits may not reflect the typical connectivity found in QAOA, VQE, quantum simulation, or other structured quantum algorithms. * Tagging in the database: In the database, you can specify the origin of your workloads, tagging them as \"random\" if appropriate. This helps others understand the context of benchmark results. When developing new partitioning strategies, we strongly encourage testing on workloads representative of your target applications rather than relying solely on random circuit benchmarks. Future Enhancements The current cut.py implementation includes several parameters that are reserved for future enhancements: Backtracking: The backtrack_window parameter is currently unused but reserved for implementing backtracking search Local search: The polish_1swap_budget parameter is disabled for HDH partitioning (as moving whole qubits is computationally heavier than single-node swaps) Predictive rejection: The predictive_reject parameter is reserved for future heuristics These features may be enabled in future versions of the library as the partitioning algorithms continue to evolve.","title":"Partitioning HDHs for distribution"},{"location":"passes/#hdh-partitioning-utilities","text":"Here is an overview of the partitioning utilities available in the HDH library, designed to distribute quantum computations across multiple devices.","title":"HDH Partitioning Utilities"},{"location":"passes/#partitioning-hdhs-for-distribution","text":"The hdh/passes directory contains scripts for partitioning and manipulating HDH graphs. The primary file for partitioning is cut.py , which offers two main approaches: a greedy, HDH-aware method and a METIS-based method operating on a qubit graph representation (telegate).","title":"Partitioning HDHs for Distribution"},{"location":"passes/#greedy-hdh-partitioner","text":"The main partitioning function is compute_cut , which implements a greedy, bin-filling algorithm with hypergraph awareness. Here's how it works:","title":"Greedy HDH Partitioner"},{"location":"passes/#core-mechanics","text":"Node-level assignment: The partitioner assigns individual nodes of the HDH graph to bins. Qubit-based capacity: While the assignment is at the node level, the capacity of each bin is determined by the number of unique qubits it contains. Automatic sibling placement: Once a node corresponding to a particular qubit is placed in a bin, all other nodes associated with that same qubit are automatically assigned to the same bin. This ensures that all temporal instances of a qubit remain co-located.","title":"Core Mechanics"},{"location":"passes/#algorithm-details","text":"The algorithm operates in two main phases: a beam-search-based bin-filling phase, followed by a round-robin mop-up phase.","title":"Algorithm Details"},{"location":"passes/#phase-1-main-bin-filling-beam-search","text":"Step 1 - Ordering and Representative Selection: Each qubit in the quantum circuit may appear at multiple time steps (e.g., qubit 0 at time 1, time 5, time 12). The algorithm: 1. Selects ONE representative node for each qubit - specifically, the node with the highest weighted degree (most connections to other operations) 2. Sorts these representatives in descending order of their weighted degrees Why? Placing highly connected qubits first gives the algorithm more context to make informed placement decisions. It's like seating the most social people at a party first - they help determine where their friends should sit. Step 2 - Beam Search for Candidate Selection: For each bin being filled, instead of greedily picking just the single best node (which might not fit due to capacity), the algorithm uses beam search to keep the top beam_k candidates. What is Beam Search? Beam search is a heuristic that balances between: - Greedy search (k=1): Only considers the single best option - fast but inflexible - Exhaustive search (k=\u221e): Considers all options - thorough but slow - Beam search (k=3 default): Keeps the top k candidates - good balance Example with 50 unassigned qubits and beam_k=3: 1. Evaluate all 50 qubits based on: - Delta cost: How much would placing this node increase cut cost? - Frontier score: How well connected is this node to nodes already in the bin? 2. Keep top 3 candidates: - Qubit 42: delta_cost=-5, frontier_score=100 (BEST) - Qubit 17: delta_cost=-4, frontier_score=95 (2nd best) - Qubit 23: delta_cost=-3, frontier_score=90 (3rd best) 3. Check capacity constraints for each in order: - Qubit 42: Would make bin have 26/25 qubits \u274c - Qubit 17: Would make bin have 25/25 qubits \u2713 - Place qubit 17! Effect of changing beam_k: - beam_k=1 : Fastest, but may miss good alternatives if the best choice violates capacity - beam_k=3 (default): Good balance - considers alternatives without much overhead - beam_k=10 : More thorough exploration, slower, potentially better quality for complex constraints","title":"Phase 1: Main Bin-Filling (Beam Search)"},{"location":"passes/#phase-1-capacity-management-the-shadow-capacity-system","text":"The algorithm uses a dynamic capacity model to encourage better load balancing across bins. How it works: With cap=25 qubits per bin and reserve_frac=0.08 : - Shadow capacity = 25 \u00d7 (1.0 - 0.08) = 23 qubits - Hard capacity = 25 qubits - 80% threshold = 25 \u00d7 0.8 = 20 qubits Qubits Currently in Bin Effective Capacity Limit Reasoning 0-19 qubits 23 (shadow limit) \"Save some room for later bins\" 20-25 qubits 25 (hard limit) \"Now you can fill to the top\" Why this helps: Without shadow capacity, early bins might greedily fill to 100%, leaving later bins with insufficient room for well-connected qubits. The shadow capacity ensures more even distribution. Example scenario with 4 bins and 100 qubits: - Without shadow capacity: Bins might fill as [25, 25, 25, 25] perfectly, but if you have 102 qubits, 2 are stranded - With shadow capacity: Bins fill as [23, 23, 23, 23] initially, then even out to [26, 25, 26, 25], accommodating all qubits better","title":"Phase 1 Capacity Management: The \"Shadow Capacity\" System"},{"location":"passes/#fallback-seeding","text":"When: If all candidates in the beam violate capacity constraints, or if no good candidates exist. What happens: The algorithm falls back to placing the first unassigned qubit representative that fits capacity, even if it's not optimal by the scoring criteria. Why necessary: Prevents the algorithm from getting stuck when beam search finds no viable candidates. Ensures bins get initialized even in difficult cases.","title":"Fallback Seeding"},{"location":"passes/#phase-2-mop-up-round-robin-distribution","text":"After the main bin-filling completes, some qubits might remain unassigned. These are distributed round-robin: For each remaining unassigned qubit: Try bins in order: 0, 1, 2, 3, 0, 1, 2, 3, ... Place in first bin with available capacity If no bins have space \u2192 qubit is not placed Example: 5 qubits left: Q1, Q2, Q3, Q4, Q5 4 bins with capacity 25: Bin 0: 24/25 qubits Bin 1: 25/25 qubits (FULL) Bin 2: 23/25 qubits Bin 3: 24/25 qubits \u2192 Q1 placed in Bin 0 (now 25/25) \u2192 Q2 skips Bin 1 (full), placed in Bin 2 (now 24/25) \u2192 Q3 placed in Bin 3 (now 25/25) \u2192 Q4 placed in Bin 2 (now 25/25) \u2192 Q5 cannot be placed - all bins full Important: The round-robin phase respects the hard capacity limit . It will NOT overfill bins. If all bins are at 100% capacity and qubits remain, those qubits are skipped (not placed). To avoid unplaced qubits: Ensure k \u00d7 cap \u2265 total_number_of_qubits when calling the partitioner.","title":"Phase 2: Mop-up (Round-Robin Distribution)"},{"location":"passes/#function-signature","text":"def compute_cut(hdh_graph, k: int, cap: int, *, beam_k: int = 3, backtrack_window: int = 0, polish_1swap_budget: int = 0, # disabled for HDH restarts: int = 1, reserve_frac: float = 0.08, predictive_reject: bool = True, seed: int = 0) -> Tuple[List[Set[str]], int] Parameters: * hdh_graph : The HDH graph to partition * k : Number of partitions (bins) * cap : Capacity per bin (in unique qubits) * beam_k : Beam width for candidate selection (default: 3) * backtrack_window : Currently unused (reserved for future enhancements) * polish_1swap_budget : Currently disabled for HDH partitioning * restarts : Number of random restarts to try (default: 1) * reserve_frac : Fraction of capacity to reserve until 80% full (default: 0.08) * predictive_reject : Currently unused (reserved for future enhancements) * seed : Random seed for reproducibility Returns: * A tuple of (bins_nodes, cost) where: * bins_nodes is a list of sets, each containing node IDs assigned to that bin * cost is the total cut cost (number of hyperedges spanning multiple bins)","title":"Function Signature"},{"location":"passes/#metis-telegate-partitioner","text":"For an alternative approach to partitioning, the library provides the metis_telegate function, which leverages the METIS algorithm (with a fallback to the Kernighan-Lin algorithm if METIS is not available).","title":"METIS Telegate Partitioner"},{"location":"passes/#telegate-graph-construction","text":"Graph transformation: This method first converts the HDH into a \"telegate\" graph using the telegate_hdh function. In this representation: Nodes are the qubits of the quantum circuit (labeled as q{idx} ). Edges represent quantum operations between qubits (i.e., their co-appearance in a quantum hyperedge). Edge weights correspond to the multiplicity of interactions between two qubits. Quantum operation filtering: Only hyperedges marked as quantum operations (with tau attribute = \"q\") are considered when building the telegate graph.","title":"Telegate Graph Construction"},{"location":"passes/#partitioning-process","text":"METIS partitioning: The telegate graph is partitioned using the nxmetis library, which provides Python bindings to the highly efficient METIS graph partitioning tool. If METIS is unavailable, the algorithm automatically falls back to the Kernighan-Lin bisection algorithm from NetworkX. METIS attempts to respect capacity constraints through the tpwgts (target partition weights) and ubvec (unbalance vector) parameters. Overflow repair: Since METIS does not guarantee perfectly balanced partitions, a greedy rebalancing algorithm ( _repair_overflow ) is used to adjust the partitions and ensure that no bin exceeds its qubit capacity. The repair algorithm uses a heuristic gain function ( _best_move_for_node ) to choose which qubits to move between bins. It prioritizes moving qubits that minimize the increase in cut edges.","title":"Partitioning Process"},{"location":"passes/#function-signature_1","text":"def metis_telegate(hdh: \"HDH\", partitions: int, capacities: int) -> Tuple[List[Set[str]], int, bool, str] Parameters: * hdh : The HDH graph to partition * partitions : Number of partitions (k) * capacities : Capacity per partition (in qubits) Returns: * A tuple of (bins_qubits, cut_cost, respects_capacity, method) where: * bins_qubits is a list of sets, each containing qubit IDs (as strings like \"q0\" , \"q1\" ) in that partition * cut_cost is the number of edges crossing between partitions (unweighted) * respects_capacity is a boolean indicating whether all bins satisfy the capacity constraint * method is either \"metis\" or \"kl\" indicating which algorithm was used","title":"Function Signature"},{"location":"passes/#cut-cost-evaluation","text":"The quality of a partition is determined by the number of \"cuts\"\u2014that is, the number of hyperedges that span across multiple bins. The library provides two functions for this purpose:","title":"Cut Cost Evaluation"},{"location":"passes/#_total_cost_hdh","text":"Calculates the total cost of a partition on an HDH graph. This function: * Iterates through all hyperedges in the HDH * Counts a hyperedge as \"cut\" if its pins (nodes) are distributed across 2 or more bins * Returns the sum of weights of all cut hyperedges * Respects edge weights if defined in the HDH graph (defaults to 1 if not specified) Algorithm: For each hyperedge, count the number of distinct bins containing at least one pin. If this count is \u2265 2, add the edge's weight to the total cost.","title":"_total_cost_hdh"},{"location":"passes/#_cut_edges_unweighted","text":"Counts the number of edges that cross between different bins in a standard graph (used for evaluating telegate graph partitions). This function: * Takes a NetworkX graph and a partition assignment * Counts edges where the two endpoints are in different bins * Returns an unweighted count (each cut edge counts as 1) Use case: This is specifically used by metis_telegate to evaluate the quality of qubit-graph partitions.","title":"_cut_edges_unweighted"},{"location":"passes/#helper-functions-and-internal-components","text":"The cut.py file contains several internal helper functions that support the main partitioning algorithms:","title":"Helper Functions and Internal Components"},{"location":"passes/#hypergraph-incidence-structure","text":"_build_hdh_incidence : Builds the incidence structure for efficient hypergraph queries _group_qnodes : Groups nodes by their associated qubit for whole-qubit placement","title":"Hypergraph Incidence Structure"},{"location":"passes/#state-management","text":"_HDHState : A class that tracks the current partition assignment, bin loads, qubit anchoring, and pin distributions during the greedy algorithm","title":"State Management"},{"location":"passes/#cost-calculation","text":"_delta_cost_hdh : Computes the incremental change in cut cost when placing a node in a bin _qubit_of : Extracts the qubit index from a node ID using regex matching","title":"Cost Calculation"},{"location":"passes/#candidate-selection","text":"_best_candidates_for_bin : Selects the top-k candidate nodes for placement using beam search _first_unassigned_rep_that_fits : Fallback function to seed bins when no good candidates are found","title":"Candidate Selection"},{"location":"passes/#graph-repair","text":"_repair_overflow : Greedy rebalancer to enforce bin capacity after METIS partitioning _best_move_for_node : Heuristic to compute the gain of moving a node between bins _over_under : Identifies which bins are over or under capacity","title":"Graph Repair"},{"location":"passes/#partitioning-utilities","text":"_kl_fallback_partition : Implements recursive Kernighan-Lin bisection as a fallback when METIS is unavailable","title":"Partitioning Utilities"},{"location":"passes/#the-partitioner-leaderboard","text":"For a detailed comparison of the performance of different partitioning strategies on various quantum circuits, please refer to the partitioner leaderboard in the repository's database . This can provide valuable insights into which partitioning method is best suited for your specific needs. See the database file in the documentation for more details.","title":"The Partitioner Leaderboard"},{"location":"passes/#notes-on-evaluating-partitioners-on-random-circuits","text":"We would like to warn users and partitioning strategy developers that we have found partitioners to behave differently on real quantum workloads when compared to randomly generated ones. As such, we recommend not testing partitioners on randomly generated workloads unless that is specifically your goal. Key considerations: * Circuit structure matters: Real quantum algorithms often have characteristic patterns (e.g., layered structures, specific qubit interaction patterns) that random circuits lack. * Connectivity patterns: Random circuits may not reflect the typical connectivity found in QAOA, VQE, quantum simulation, or other structured quantum algorithms. * Tagging in the database: In the database, you can specify the origin of your workloads, tagging them as \"random\" if appropriate. This helps others understand the context of benchmark results. When developing new partitioning strategies, we strongly encourage testing on workloads representative of your target applications rather than relying solely on random circuit benchmarks.","title":"Notes on Evaluating Partitioners on Random Circuits"},{"location":"passes/#future-enhancements","text":"The current cut.py implementation includes several parameters that are reserved for future enhancements: Backtracking: The backtrack_window parameter is currently unused but reserved for implementing backtracking search Local search: The polish_1swap_budget parameter is disabled for HDH partitioning (as moving whole qubits is computationally heavier than single-node swaps) Predictive rejection: The predictive_reject parameter is reserved for future heuristics These features may be enabled in future versions of the library as the partitioning algorithms continue to evolve.","title":"Future Enhancements"},{"location":"vis/","text":"Visualising HDHs plot_hdh renders an HDH as a time-vs-index diagram, showing how q uantum and c lassical states evolve across timesteps and how hyperedges connect them. plot_hdh(hdh: HDH, save_path: str | None = None) -> None The function returns nothing, and shows the HDH in a python window unless a save_path = hdh.png is set. In this case the image will be directly saved to the input path. It can be used on any HDH, after it is generated from model instructions: import hdh from hdh.models.qca import QCA from hdh.visualize import plot_hdh # Topology of lattice over which QCA will evolve topology = { \"q0\": [\"q1\", \"q2\"], \"q1\": [\"q0\"], \"q2\": [\"q0\"] } measurements = {\"q1\", \"q2\"} qca = QCA(topology=topology, measurements=measurements, steps=3) hdh = qca.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH or directly from \"manually\" defining all nodes and hyperedges of a HDH: import hdh from hdh.hdh import HDH from hdh.visualize import plot_hdh hdh = HDH() # swap hdh.add_node(\"q1_t0\",\"q\",0) hdh.add_node(\"q3_t0\",\"q\",0) hdh.add_node(\"q1_t1\",\"q\",1) hdh.add_node(\"q3_t1\",\"q\",1) hdh.add_node(\"q1_t2\",\"q\",2) hdh.add_node(\"q3_t2\",\"q\",2) hdh.add_node(\"q1_t3\",\"q\",3) hdh.add_node(\"q3_t3\",\"q\",3) hdh.add_hyperedge([\"q1_t0\", \"q1_t1\"], \"q\") hdh.add_hyperedge([\"q3_t0\", \"q3_t1\"], \"q\") hdh.add_hyperedge([\"q1_t1\", \"q3_t1\", \"q1_t2\", \"q3_t2\"], \"q\") hdh.add_hyperedge([\"q1_t2\", \"q1_t3\"], \"q\") hdh.add_hyperedge([\"q3_t2\", \"q3_t3\"], \"q\") # # cnot hdh.add_node(\"q0_t4\",\"q\",4) hdh.add_node(\"q0_t3\",\"q\",3) hdh.add_node(\"q0_t2\",\"q\",2) hdh.add_node(\"q1_t4\",\"q\",4) hdh.add_node(\"q0_t5\",\"q\",5) hdh.add_node(\"q1_t5\",\"q\",5) hdh.add_hyperedge([\"q0_t2\", \"q0_t3\"], \"q\") hdh.add_hyperedge([\"q1_t3\", \"q1_t4\", \"q0_t3\", \"q0_t4\"], \"q\") hdh.add_hyperedge([\"q0_t4\", \"q0_t5\"], \"q\") hdh.add_hyperedge([\"q1_t4\", \"q1_t5\"], \"q\") # meas hdh.add_node(\"c1_t6\",\"c\",6) hdh.add_node(\"q3_t7\",\"q\",7) hdh.add_node(\"q2_t7\",\"q\",7) hdh.add_hyperedge([\"c1_t6\", \"q1_t5\"], \"c\") hdh.add_hyperedge([\"c1_t6\", \"q3_t7\"], \"c\") hdh.add_hyperedge([\"c1_t6\", \"q2_t7\"], \"c\") # target cnot hdh.add_node(\"q3_t8\",\"q\",8) hdh.add_node(\"q4_t8\",\"q\",8) hdh.add_node(\"q3_t9\",\"q\",9) hdh.add_node(\"q4_t9\",\"q\",9) hdh.add_node(\"q4_t7\",\"q\",7) hdh.add_node(\"q4_t10\",\"q\",10) hdh.add_node(\"q3_t10\",\"q\",10) hdh.add_hyperedge([\"q3_t8\", \"q4_t8\",\"q3_t9\", \"q4_t9\"], \"q\") hdh.add_hyperedge([\"q3_t8\", \"q3_t7\"], \"q\") hdh.add_hyperedge([\"q4_t8\", \"q4_t7\"], \"q\") hdh.add_hyperedge([\"q4_t9\", \"q4_t10\"], \"q\") hdh.add_hyperedge([\"q3_t9\", \"q3_t10\"], \"q\") # h gate hdh.add_node(\"q3_t11\",\"q\",11) hdh.add_hyperedge([\"q3_t10\",\"q3_t11\"], \"q\") # meas hdh.add_node(\"q0_t13\",\"q\",13) hdh.add_node(\"c3_t12\",\"c\",12) hdh.add_hyperedge([\"c3_t12\", \"q3_t11\"], \"c\") hdh.add_hyperedge([\"c3_t12\", \"q0_t13\"], \"c\") hdh.add_hyperedge([\"q0_t5\", \"q0_t13\"], \"q\") fig = plot_hdh(hdh,save_path=\"test2.png\") # Visualize HDH A few things to note about the HDH visualizations: Index ordering : y-positions are \u201cflipped\u201d so that the largest index appears at the bottom of the axis, while tick labels still increase upward. This matches typical circuit diagrams where q0 is drawn at the top. This is consistent with popular quantum packages, and allows for users to \"read\" from top to bottom. Participation filter : nodes not present in any edge are omitted from the plot to reduce clutter. Style inference : if the hyperedge type is not defined for an edge, it is inferred from its output nodes (if one of the nodes is classical it assumes classical, otherwise it defaults to quantum). Same-timestep edges : are not drawn (to avoid the misconception that cuts can occur \"instantaneously\" -> they require communication primitives and thus operations spanning different partitions must have experienced a cut previous to their execution). Lazy qubit appearance : qubits appear in the diagram only when first used in an operation. Their initialization motifs (e.g. in the Circuit model) are delayed until one timestep before the first gate on that qubit. This reduces clutter from unused wires. Example: in the HDH above, qubit 4 only begins appearing from timestep 7.","title":"Visualizing HDHs"},{"location":"vis/#visualising-hdhs","text":"plot_hdh renders an HDH as a time-vs-index diagram, showing how q uantum and c lassical states evolve across timesteps and how hyperedges connect them. plot_hdh(hdh: HDH, save_path: str | None = None) -> None The function returns nothing, and shows the HDH in a python window unless a save_path = hdh.png is set. In this case the image will be directly saved to the input path. It can be used on any HDH, after it is generated from model instructions: import hdh from hdh.models.qca import QCA from hdh.visualize import plot_hdh # Topology of lattice over which QCA will evolve topology = { \"q0\": [\"q1\", \"q2\"], \"q1\": [\"q0\"], \"q2\": [\"q0\"] } measurements = {\"q1\", \"q2\"} qca = QCA(topology=topology, measurements=measurements, steps=3) hdh = qca.build_hdh() # Generate HDH fig = plot_hdh(hdh) # Visualize HDH or directly from \"manually\" defining all nodes and hyperedges of a HDH: import hdh from hdh.hdh import HDH from hdh.visualize import plot_hdh hdh = HDH() # swap hdh.add_node(\"q1_t0\",\"q\",0) hdh.add_node(\"q3_t0\",\"q\",0) hdh.add_node(\"q1_t1\",\"q\",1) hdh.add_node(\"q3_t1\",\"q\",1) hdh.add_node(\"q1_t2\",\"q\",2) hdh.add_node(\"q3_t2\",\"q\",2) hdh.add_node(\"q1_t3\",\"q\",3) hdh.add_node(\"q3_t3\",\"q\",3) hdh.add_hyperedge([\"q1_t0\", \"q1_t1\"], \"q\") hdh.add_hyperedge([\"q3_t0\", \"q3_t1\"], \"q\") hdh.add_hyperedge([\"q1_t1\", \"q3_t1\", \"q1_t2\", \"q3_t2\"], \"q\") hdh.add_hyperedge([\"q1_t2\", \"q1_t3\"], \"q\") hdh.add_hyperedge([\"q3_t2\", \"q3_t3\"], \"q\") # # cnot hdh.add_node(\"q0_t4\",\"q\",4) hdh.add_node(\"q0_t3\",\"q\",3) hdh.add_node(\"q0_t2\",\"q\",2) hdh.add_node(\"q1_t4\",\"q\",4) hdh.add_node(\"q0_t5\",\"q\",5) hdh.add_node(\"q1_t5\",\"q\",5) hdh.add_hyperedge([\"q0_t2\", \"q0_t3\"], \"q\") hdh.add_hyperedge([\"q1_t3\", \"q1_t4\", \"q0_t3\", \"q0_t4\"], \"q\") hdh.add_hyperedge([\"q0_t4\", \"q0_t5\"], \"q\") hdh.add_hyperedge([\"q1_t4\", \"q1_t5\"], \"q\") # meas hdh.add_node(\"c1_t6\",\"c\",6) hdh.add_node(\"q3_t7\",\"q\",7) hdh.add_node(\"q2_t7\",\"q\",7) hdh.add_hyperedge([\"c1_t6\", \"q1_t5\"], \"c\") hdh.add_hyperedge([\"c1_t6\", \"q3_t7\"], \"c\") hdh.add_hyperedge([\"c1_t6\", \"q2_t7\"], \"c\") # target cnot hdh.add_node(\"q3_t8\",\"q\",8) hdh.add_node(\"q4_t8\",\"q\",8) hdh.add_node(\"q3_t9\",\"q\",9) hdh.add_node(\"q4_t9\",\"q\",9) hdh.add_node(\"q4_t7\",\"q\",7) hdh.add_node(\"q4_t10\",\"q\",10) hdh.add_node(\"q3_t10\",\"q\",10) hdh.add_hyperedge([\"q3_t8\", \"q4_t8\",\"q3_t9\", \"q4_t9\"], \"q\") hdh.add_hyperedge([\"q3_t8\", \"q3_t7\"], \"q\") hdh.add_hyperedge([\"q4_t8\", \"q4_t7\"], \"q\") hdh.add_hyperedge([\"q4_t9\", \"q4_t10\"], \"q\") hdh.add_hyperedge([\"q3_t9\", \"q3_t10\"], \"q\") # h gate hdh.add_node(\"q3_t11\",\"q\",11) hdh.add_hyperedge([\"q3_t10\",\"q3_t11\"], \"q\") # meas hdh.add_node(\"q0_t13\",\"q\",13) hdh.add_node(\"c3_t12\",\"c\",12) hdh.add_hyperedge([\"c3_t12\", \"q3_t11\"], \"c\") hdh.add_hyperedge([\"c3_t12\", \"q0_t13\"], \"c\") hdh.add_hyperedge([\"q0_t5\", \"q0_t13\"], \"q\") fig = plot_hdh(hdh,save_path=\"test2.png\") # Visualize HDH A few things to note about the HDH visualizations: Index ordering : y-positions are \u201cflipped\u201d so that the largest index appears at the bottom of the axis, while tick labels still increase upward. This matches typical circuit diagrams where q0 is drawn at the top. This is consistent with popular quantum packages, and allows for users to \"read\" from top to bottom. Participation filter : nodes not present in any edge are omitted from the plot to reduce clutter. Style inference : if the hyperedge type is not defined for an edge, it is inferred from its output nodes (if one of the nodes is classical it assumes classical, otherwise it defaults to quantum). Same-timestep edges : are not drawn (to avoid the misconception that cuts can occur \"instantaneously\" -> they require communication primitives and thus operations spanning different partitions must have experienced a cut previous to their execution). Lazy qubit appearance : qubits appear in the diagram only when first used in an operation. Their initialization motifs (e.g. in the Circuit model) are delayed until one timestep before the first gate on that qubit. This reduces clutter from unused wires. Example: in the HDH above, qubit 4 only begins appearing from timestep 7.","title":"Visualising HDHs"},{"location":"why/","text":"Why HDHs? Hybrid Dependency Hypergraphs provide a model-agnostic abstraction for quantum computation.Their purpose is to enable distributed quantum computing, meaning the collaboration of various quantum computers to complete a task greater than their individual capacities. Different quantum computers work with different computational models due to physical constraints or architectural choices.For example, photonic systems do not naturally support the circuit model because photons interact weakly, while superconducting devices commonly use circuits but can support cellular automata or quantum walks when those models map better to the task. HDHs encode not only these models, but also the hybrid nature of quantum processing, where classical control and classical-quantum feedback loops are intrinsic.This also enables the representation of hybrid algorithms, which currently deliver the most practical gains. HDHs sit between high-level quantum programming languages and machine-level instructions.Because they are based on quantum models, they provide a familiar representation for developers and accurately capture workload structure and weight. These properties make the abstraction powerful, as it enables the creation of a dependency pattern from any quantum workload.These patterns can then be partitioned (or cut) and distributed to the different devices collaborating to complete the task. The notion of partitioning computation at a hypergraph level predates quantum computing and has been explored in HPC, without much success.The difference is that quantum computation uniquely exposes explicit dependency structures in its models.This enables well-defined and meaningful partitioning, contrary to classical settings where dependencies can be implicit and costly to infer.The idea of using hypergraph partitioning for distribution has circulated in the quantum community since at least 2018.HDHs aim to serve as a baseline abstraction over which partitioning techniques can be evaluated fairly. State-of-the-art hypergraph partitioning techniques used in this context include KaHyPar and Fiduccia\u2013Mattheyses.However, we do not yet have a good understanding of how well these and other partitioners compare across the recurring dependency structures that arise in quantum computing.Current efforts rely on ad-hoc, independently constructed representations, which makes cross-method evaluation difficult.HDHs aim to make the construction of these patterns simple, transparent, and fast, enabling systematic comparison of existing partitioners and supporting the development of specialised techniques for distributed quantum workloads. It is important to note that the goal of HDHs is not to establish or model the physical quantum communication layer, nor to define classical channels between devices when no quantum connection exists.Those aspects are valuable for full-stack evaluation, and future versions will include quantum communication primitives, but HDHs focus first on the abstraction of computation, not the transport layer. Similarly, HDHs do not prescribe partitioning strategies.Their role is to provide a fair, consistent substrate on which partitioning techniques can be applied and compared.We will provide reference implementations for standard and emerging partitioners, and record partitioning outcomes in our database to enable systematic, cross-method evaluation.","title":"Why HDHs?"},{"location":"why/#why-hdhs","text":"Hybrid Dependency Hypergraphs provide a model-agnostic abstraction for quantum computation.Their purpose is to enable distributed quantum computing, meaning the collaboration of various quantum computers to complete a task greater than their individual capacities. Different quantum computers work with different computational models due to physical constraints or architectural choices.For example, photonic systems do not naturally support the circuit model because photons interact weakly, while superconducting devices commonly use circuits but can support cellular automata or quantum walks when those models map better to the task. HDHs encode not only these models, but also the hybrid nature of quantum processing, where classical control and classical-quantum feedback loops are intrinsic.This also enables the representation of hybrid algorithms, which currently deliver the most practical gains. HDHs sit between high-level quantum programming languages and machine-level instructions.Because they are based on quantum models, they provide a familiar representation for developers and accurately capture workload structure and weight. These properties make the abstraction powerful, as it enables the creation of a dependency pattern from any quantum workload.These patterns can then be partitioned (or cut) and distributed to the different devices collaborating to complete the task. The notion of partitioning computation at a hypergraph level predates quantum computing and has been explored in HPC, without much success.The difference is that quantum computation uniquely exposes explicit dependency structures in its models.This enables well-defined and meaningful partitioning, contrary to classical settings where dependencies can be implicit and costly to infer.The idea of using hypergraph partitioning for distribution has circulated in the quantum community since at least 2018.HDHs aim to serve as a baseline abstraction over which partitioning techniques can be evaluated fairly. State-of-the-art hypergraph partitioning techniques used in this context include KaHyPar and Fiduccia\u2013Mattheyses.However, we do not yet have a good understanding of how well these and other partitioners compare across the recurring dependency structures that arise in quantum computing.Current efforts rely on ad-hoc, independently constructed representations, which makes cross-method evaluation difficult.HDHs aim to make the construction of these patterns simple, transparent, and fast, enabling systematic comparison of existing partitioners and supporting the development of specialised techniques for distributed quantum workloads. It is important to note that the goal of HDHs is not to establish or model the physical quantum communication layer, nor to define classical channels between devices when no quantum connection exists.Those aspects are valuable for full-stack evaluation, and future versions will include quantum communication primitives, but HDHs focus first on the abstraction of computation, not the transport layer. Similarly, HDHs do not prescribe partitioning strategies.Their role is to provide a fair, consistent substrate on which partitioning techniques can be applied and compared.We will provide reference implementations for standard and emerging partitioners, and record partitioning outcomes in our database to enable systematic, cross-method evaluation.","title":"Why HDHs?"}]}